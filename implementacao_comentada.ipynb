{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33256fce",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5157e0a",
   "metadata": {},
   "source": [
    "### Iniciando processo\n",
    "Definição das constantes - caminho do dataset e nomes das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARQUIVOS\n",
    "ATTRIBUTES_FILE = './dataset/attributes.csv'\n",
    "LABELS_FILE = './dataset/label.csv'\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: 'Normal',\n",
    "    1: 'Charge',\n",
    "    2: 'Discharge',\n",
    "    3: 'Friction',\n",
    "    4: 'Charge Discharge',\n",
    "    5: 'Charge Friction',\n",
    "    6: 'Discharge Friction',\n",
    "    7: 'Charge Discharge Friction'\n",
    "}\n",
    "\n",
    "nomes_classes = list(CLASS_NAMES.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2c8e8",
   "metadata": {},
   "source": [
    "Os números gerados aleatoriamente pelo computador na verdade são pseudo-aleatórios. Assim, setar uma random seed constante faz com que os pesos iniciais, que são gerados aleatoriamente primeiro, sejam sempre iniciados com o mesmo valor aleatório. Para isso, travamos a aleatoriedade do numPy e do TensorFlow com .seed e set_seed. Isso trava os resultados da rede neural em sempre uma mesma acurácia.\n",
    "\n",
    "42 é só um número atoa, ele na verdade vem da resposta para a Questão Fundamental da Vida, do Universo e Tudo Mais - O Guia do Mochileiro das Galáxias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para os dados aleatorios se repetirem\n",
    "np.random.seed(24)\n",
    "tf.random.set_seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ea797",
   "metadata": {},
   "source": [
    "### carrega_dados\n",
    "\n",
    "**X.shape[0]**: número de linhas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de amostras disponíveis.\n",
    "\n",
    "**X.shape[1]**: número de colunas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de colunas do csv de amostras. ou seja, quantas variações de tempo uma única amostra possui. \n",
    "\n",
    "**X**: \n",
    "| Amostra | feature_1 | feature_2 | ... | feature_201  |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| amostra 1 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 2 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 3 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "|  ...      |       ...        |         ...      | ... |           ...      |\n",
    "\n",
    "**tf.keras.utils.to_categorical(y, num_classes=num_classes)**: converte rótulos de classes inteiros para formato one-hot encoded. é armazenado em uma array numPy. seu tamanho é linhas_amostras x nro_classes. \n",
    "\n",
    "**y_categorical**:\n",
    "| Amostra | Neurônio 1 (Normal) | Neurônio 2 (Charge) | ... | Neurônio 8 (All Faults) |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| Linha 1 | 1 | 0 | ... | 0 |\n",
    "| Linha 2 | 0 | 0 | ... | 1 |\n",
    "| Linha 3 | 0 | 0 | ... | 0 |\n",
    "|  ...    | 0 | 0 | ... | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7315d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(attr_caminho, lbl_caminho):\n",
    "\n",
    "    print(f\"Lendo atributos: {attr_caminho}\")\n",
    "    print(f\"Lendo labels: {lbl_caminho}\")\n",
    "    \n",
    "    X_df = pd.read_csv(attr_caminho)\n",
    "    y_df = pd.read_csv(lbl_caminho)\n",
    "\n",
    "    # converte para vetor\n",
    "    X = X_df.values\n",
    "    y = y_df.values.flatten() \n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    print(f\"Dataset carregado com sucesso:\")\n",
    "    print(f\" - Amostras: {X.shape[0]}\")\n",
    "    print(f\" - Features (Timestamps): {num_features}\")\n",
    "    print(f\" - Classes únicas encontradas: {num_classes} {np.unique(y)}\")\n",
    "\n",
    "    # One-hot para redes neurais\n",
    "    y_categorical = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "    \n",
    "    return X, y_categorical, y, num_features, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc5f0c",
   "metadata": {},
   "source": [
    "### constroi_mlp\n",
    "\n",
    "Define as arquiteturas das MLP usadas no artigo. A função recebe o nome da configuração, a forma de entrada (timestamps do dataset) e número de classes de saída. \n",
    "\n",
    "**models.Sequential()**: cria um objeto do tipo modelo sequencial -> camadas da rede serão empilhadas uma após a outra em ordem. \n",
    "\n",
    "**model.add(layers.InputLayer(shape=shape))**: define camada de entrada com o formato de entrada dos dados. O argumento shape informa a rede o número de features que ela receberá.\n",
    "\n",
    "**estrutura do if**: o if definirá a camada oculta com base no nome da configuração. Se for X neurônios, model.add(layers.Dense(X, activation='relu')) adiciona uma camada densa com X neurônios e a função de ativação ReLU. Por fim, a camada de saída é comum a todas as redes com o número de neurônios exatamente igual ao número de classes (8). A função de ativação dessa camada é a Softmax, que transforma os scores internos em probabilidades para cada classe.\n",
    "\n",
    "Por fim, a função *constroi_mlp()* retorna o objeto model (ou seja, retorna um modelo de aprendizado) completo e pronto para treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ae7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELOS (Tópico 3.4)\n",
    "\n",
    "def constroi_mlp(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == '4N':\n",
    "        model.add(layers.Dense(4, activation='relu'))\n",
    "    elif config_name == '8N':\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '16N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "    elif config_name == '32N':\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif config_name == '16-8N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '8-8-8N_autoral':\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '32N_autoral':\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif config_name == '16N_autoral':\n",
    "        model.add(layers.Dense(16, activation='sigmoid'))\n",
    "    elif config_name == 'worst_network':\n",
    "        model.add(layers.Dense(4, activation='relu'))\n",
    "        \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d600a6",
   "metadata": {},
   "source": [
    "### constroi_cnn\n",
    "\n",
    "A função define as arquiteturas das CNN usadas no artigo. Recebe o nome da configuração (Mx), o formato da entrada (no nosso caso, 201 timestamps de pressão do dataset) e o número de classes (8 no nosso caso).\n",
    "\n",
    "**models.Sequential()**: cria uma pilha linear de camadas em que os dados fluem sequencialmente de uma camada para outra.\n",
    "\n",
    "**model.add(layers.InputLayer(shape=shape))**: a rede receberá um vetor com a forma informada na função, ou seja, receberá um vetor de 201 pontos de pressão regulada conforme nosso dataset.\n",
    "\n",
    "**bloco if**: primeiramente seleciona a configuração base Mx. A base da M1 até a M4 é a seguinte, em que **A**, **B** e **C** são parâmetros fornecidos pelo artigo:\n",
    "```python\n",
    "if config == Mx, em que x = número de 1 a 4:\n",
    "    model.add(layers.Conv1D(filters=**A**, kernel_size=**B**, padding='same')) \n",
    "    # Adiciona camada de convolução 1D. Aplica **A** filtro(s) deslizante(s) com o tamanho de janela de **B** pontos temporais. Isso extrai características locais da curva de presão. \n",
    "    model.add(layers.AveragePooling1D(pool_size=**C**))\n",
    "    # Adiciona a camada de pooling reduzindo a dimensão dos dados tirando média a cada **C** pontos.\n",
    "    model.add(layers.Flatten())\n",
    "    # Adiciona camada de achatamento transformando a matriz resultante das convoluções em um vetor longo e único para entrar na camada densa\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    # Por fim, adiciona camada densa intermediária antes da fully-connected com processamento de 16 neurônios e ReLU de ativação, sendo um padrão em todas as CNNs testadas no artigo.\n",
    "    # A camada M5 possui um segundo bloco de camada de convolução 1D e pooling, ou seja, a rede é mais profunda. \n",
    "model.add(layers.Dense(num_classes, activation='softmax')) # Todas as camadas Mx, da 1 até a 5, recebem a última camada de saída com o número de neurônios = número de classes com ativação Softmax.\n",
    "```\n",
    "Por fim, a função retorna o modelo de aprendizado construído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0591fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constroi_cnn(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == 'M1':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M2':\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M3':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=16)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M4':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=8))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M5':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "     \n",
    "    elif config_name == 'M6_autoral': #Modelo M1 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M7_autoral': #Modelo M2 com tanh\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M8_autoral': #Modelo M3 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=16)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M9_autoral': #Modelo M4 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=8))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M10_autoral': #Modelo M5 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "\n",
    "    elif config_name == 'M11_autoral': #Modelo maior com tanh\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=16, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(32, activation='tanh'))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d65d9e",
   "metadata": {},
   "source": [
    "### Experimentação\n",
    "\n",
    "Primeiramente há o carregamento dos dados por meio da função carrega_dados() anteriormente discutida. Há o retorno das variáveis:\n",
    "- **X**: matriz com as 8000 amostras de pressão.\n",
    "- **y_cat**: rótulos das categorias de classificação no formato one-hot encoded.\n",
    "- **y_integers**: rótulos das categorias em formato original para usar na estratificação da validação cruzada.\n",
    "- **n_features**: número de momentos diferentes da mesma pressão, no caso, 201.\n",
    "- **n_classes**: quantas classes o problema de classificação possui.\n",
    "\n",
    "**Separação do dataset**: é por meio da função train_test_split(). A função recebe o dataset inteiro (**X**), os rótulos das categorias hot encoded (**y_cat**), os rótulos das categorias inteiros (**y_integers**), o tamanho do dataset de teste pretendido, nesse caso, 10% ou seja, **test_size = 0.10**. O dataset de teste nunca encontrará o dataset de treino, essa função garante que a informação testada nunca tenha sido reconhecida pelo modelo anteriormente. O atributo **stratify** da função garante a amostragem estratificada mantendo a mesma proporção de falhas tanto no treino quanto no teste. Ele recebe y_integers como valor, ou seja, identifica-se quantas classes devem ser garantidas na mesma porcentagem. O **random_state = 0.42** garante que a divisão seja sempre a mesma. Por fim, a função devolve o dataset de treino em **X_train**, o dataset de teste em **X_test**, as classes de treino em **y_train**, as classes de teste em **y_test** tanto em hot encoded quanto em inteiros (**y_train_int** e **y_test_int**).\n",
    "\n",
    "**Preparação de dados para a CNN**: as matrizes de dados **X_train** e **X_test** não estão no formato esperado pelas camadas convolucionais (Conv1D) da biblioteca Keras, que exigem uma entrada tridimensional (amostras, timesteps, canais). Por isso, utiliza-se a função reshape() para adicionar uma dimensão extra de tamanho 1 ao final, representando o único canal da série temporal. As novas variáveis **X_train_cnn** e **X_test_cnn** assumem o formato (amostras, 201, 1).\n",
    "\n",
    "**Definição dos formatos de entrada**: são criadas as tuplas **mlp_shape** e **cnn_shape** para informar à primeira camada de cada rede qual o formato dos dados que entrarão. Para o MLP é um vetor plano de (201,) e para a CNN é a estrutura de (201, 1).\n",
    "\n",
    "**Definição de Hiperparâmetros**: são estabelecidas as constantes que guiarão o processo de treinamento:\n",
    "- **EPOCHS** = 50: define que o modelo passará pelo dataset completo 50 vezes durante o treino.\n",
    "- **BATCH_SIZE** = 32: indica que os pesos da rede serão atualizados a cada 32 amostras processadas.\n",
    "- **K_FOLDS** = 10: define que a validação cruzada dividirá os dados de treino em 10 partes distintas.\n",
    "\n",
    "**Configuração da Validação Cruzada**: inicializa-se uma lista vazia resultados para armazenar as métricas de cada rodada. O objeto **skf** é instanciado usando a classe StratifiedKFold. Ele é configurado com **n_splits=10** (para dividir em 10 partes), **shuffle=True** (para embaralhar os dados antes da divisão e evitar viés de ordem) e **random_state=42** (para garantir a reprodutibilidade dos folds). Esse objeto não divide os dados imediatamente, mas define a lógica que será usada no loop de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTOS\n",
    "    \n",
    "X, y_cat, y_integers, n_features, n_classes = carrega_dados(ATTRIBUTES_FILE, LABELS_FILE)\n",
    "\n",
    "# divisao treino/teste (10% Teste)\n",
    "X_train, X_test, y_train, y_test, y_train_int, y_test_int = train_test_split(\n",
    "    X, y_cat, y_integers, test_size=0.10, stratify=y_integers, random_state=24\n",
    ")\n",
    "\n",
    "# CNN: (samples, timesteps, features=1)\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "mlp_shape = (n_features,)\n",
    "cnn_shape = (n_features, 1)\n",
    "\n",
    "EPOCHS = 50 \n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 10\n",
    "\n",
    "resultados = []\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=24)\n",
    "\n",
    "print(f\"\\nIniciando Validação Cruzada (K={K_FOLDS})...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f20a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para guardar as médias de loss de cada configuração\n",
    "\n",
    "historico_perdas = {'MLP': {}, 'CNN': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fa893",
   "metadata": {},
   "source": [
    "### Rodando as arquiteturas MLP\n",
    "\n",
    "**Avaliação das Topologias e Configurações**: Define-se a lista configuracoes_mlp contendo as chaves das arquiteturas a serem testadas. A lista foi expandida para incluir não apenas as variações de neurônios (e.g., '32N', '4N'), mas também configurações autorais (e.g., '32N_autoral') e cenários de controle (e.g., 'worst_network'). O loop principal percorre cada cfg, executando tf.keras.backend.clear_session() no início para liberar memória e reinicializando as listas loss_train_folds e loss_val_folds para o rastreamento das curvas de aprendizado.\n",
    "\n",
    "**Loop de Validação Cruzada**: Utiliza-se o método skf.split() aplicado aos dados de treino (X_train) e rótulos inteiros (y_train_int). A cada iteração (fold), os índices gerados separam os dados em subconjuntos de treino (X_fold_train, y_fold_train) e validação (X_fold_val, y_fold_val).\n",
    "\n",
    "**Compilação e Treinamento Condicional**: A construção e o treinamento do modelo variam conforme a configuração cfg selecionada, permitindo estratégias de otimização distintas:\n",
    "\n",
    "    Configuração '32N_autoral': Aplica-se uma estratégia mais robusta. O otimizador é o Adam (learning rate de 0.001) e a função de perda utiliza CategoricalCrossentropy com label_smoothing de 0.1 para evitar overfitting. Adicionalmente, implementa-se o callback ReduceLROnPlateau, que reduz a taxa de aprendizado (fator 0.2) se a perda de validação estagnar por 2 épocas.\n",
    "\n",
    "    Configuração 'worst_network': Define-se um cenário de teste adverso ou base, utilizando o otimizador SGD com uma taxa de aprendizado agressiva (0.2) e função de perda padrão.\n",
    "\n",
    "    Demais Configurações: Seguem a estratégia padrão com otimizador Adam e função de perda categorical_crossentropy simples.\n",
    "\n",
    "Em todos os casos, o treinamento é executado via model.fit() com monitoramento dos dados de validação (validation_data), salvando o processo no objeto history.\n",
    "\n",
    "**Armazenamento e Suavização das Curvas**: As curvas de perda de treino e validação são extraídas a cada fold. O dicionário historico_perdas['MLP'][cfg] é atualizado calculando-se a média (np.mean) dessas curvas ao longo dos folds, resultando em uma visualização suavizada do comportamento da rede para aquela configuração.\n",
    "\n",
    "**Coleta de Métricas e Consolidação**: Após o treinamento de cada fold, o modelo é avaliado com model.evaluate() nos dados de validação, e a acurácia é salva na lista rel_acuracia. Ao final da validação cruzada, calculam-se a média (mean_acc) e o desvio padrão (std_acc) das acurácias. Esses valores são impressos no console e anexados à lista resultados, documentando o desempenho geral da topologia testada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "configuracoes_mlp = ['worst_network','32N_autoral', '32N', '4N', '8N', '16N', '16N_autoral', '16-8N', '8-8-8N_autoral']\n",
    "\n",
    "for cfg in configuracoes_mlp: \n",
    "    print(f\"Avaliando MLP: {cfg}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    rel_acuracia = []\n",
    "\n",
    "    loss_train_folds = [] # acumula curvas dos folds de treino\n",
    "    loss_val_folds = [] # acumula curvas dos folds de validation\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_mlp(cfg, mlp_shape, n_classes)\n",
    "\n",
    "        if(cfg=='32N_autoral'):\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "            reducao_taxa_aprendizado = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                         factor=0.2, \n",
    "                                                         patience=2, \n",
    "                                                         min_lr=1e-7) # patience = nro de epocas que a lr estará ativa\n",
    "\n",
    "            model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val),\n",
    "                callbacks=[reducao_taxa_aprendizado]\n",
    "            )\n",
    "        elif(cfg=='worst_network'):\n",
    "            opt = tf.keras.optimizers.SGD(learning_rate=0.2)\n",
    "            #reducao_taxa_aprendizado = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5)\n",
    "            model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val)\n",
    "            )\n",
    "        else:\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val)\n",
    "            ) # acrescentado atributo validation_data para guardar cada dado de validação gerado no fit\n",
    "\n",
    "\n",
    "        loss_train_folds.append(history.history['loss'])\n",
    "        loss_val_folds.append(history.history['val_loss'])\n",
    "\n",
    "        historico_perdas['MLP'][cfg] = {\n",
    "            'train': np.mean(loss_train_folds, axis=0),\n",
    "            'val': np.mean(loss_val_folds, axis=0)\n",
    "        } # média das curvas entre os 10 folds para suavizar a curva\n",
    "\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuracia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'MLP', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b476bf2",
   "metadata": {},
   "source": [
    "### Rodando as arquiteturas CNN\n",
    "\n",
    "**Avaliação das topologias CNN**: estabelece-se a lista **configuracoes_cnn** com as variações de arquitetura descritas no estudo, indo de 'M1' a 'M5'. O loop principal percorre cada configuração **cfg**. Antes de iniciar os folds, executa-se **tf.keras.backend.clear_session()** para liberar a memória da GPU/CPU, evitando vazamento de estados entre modelos. Inicializam-se também as listas **loss_train_folds** e **loss_val_folds** para acumular o histórico de aprendizado.\n",
    "\n",
    "**Loop de Validação Cruzada**: repete-se a lógica de divisão utilizada anteriormente com o método **skf.split()**, garantindo que os mesmos índices de folds sejam usados, o que permite uma comparação justa entre MLP e CNN. A diferença crucial ocorre no fatiamento dos dados: as variáveis **X_fold_train** e **X_fold_val** são extraídas da matriz **X_train_cnn** (previamente redimensionada para 3 dimensões), enquanto os rótulos **y_fold_train** e **y_fold_val** continuam vindo do vetor original **y_train**.\n",
    "\n",
    "**Construção e Treinamento com Monitoramento**: a cada iteração do fold, o modelo é instanciado pela função **constroi_cnn()** e compilado com otimizador **adam** e perda **categorical_crossentropy**. O ajuste dos pesos via **model.fit()** recebe um argumento adicional crucial: **validation_data=(X_fold_val, y_fold_val)**. Isso força o modelo a calcular a perda nos dados de validação ao final de cada época, sem treinar neles. O objeto de retorno é capturado na variável **historico**.\n",
    "\n",
    "**Armazenamento das Curvas de Perda**: extraem-se os vetores de perda de treino e validação do objeto **historico**, acumulando-os nas listas temporárias. Ao fim de cada fold, armazena-se no dicionário global **historico_perdas['CNN']** a média aritmética dessas curvas (**np.mean(..., axis=0)**). Esse procedimento suaviza as oscilações naturais de cada fold individual, gerando uma curva representativa do comportamento daquela arquitetura.\n",
    "\n",
    "**Coleta de Métricas e Agregação**: o desempenho final do modelo no fold é medido através de **model.evaluate()**, salvando a acurácia na lista **rel_acuracia**. Ao final do ciclo de 10 folds, computam-se a média (**mean_acc**) e o desvio padrão (**std_acc**). Os dados são estruturados e anexados à lista geral **resultados**, permitindo a comparação direta de performance com os modelos MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "configuracoes_cnn = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6_autoral', 'M7_autoral', 'M8_autoral', 'M9_autoral', 'M10_autoral', 'M11_autoral']\n",
    "\n",
    "for cfg in configuracoes_cnn:\n",
    "    print(f\"Avaliando CNN: {cfg}\")\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    loss_train_folds = [] # acumula curvas dos folds de treino\n",
    "    loss_val_folds = [] # acumula curvas dos folds de validation\n",
    "\n",
    "    rel_acuracia = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train_cnn[train_idx], X_train_cnn[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_cnn(cfg, cnn_shape, n_classes)\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=0,\n",
    "            validation_data=(X_fold_val, y_fold_val)\n",
    "        ) # acrescentado atributo validation_data para guardar cada dado de validação gerado no fit\n",
    "\n",
    "        loss_train_folds.append(history.history['loss'])\n",
    "        loss_val_folds.append(history.history['val_loss'])\n",
    "\n",
    "        historico_perdas['CNN'][cfg] = {\n",
    "            'train': np.mean(loss_train_folds, axis=0),\n",
    "            'val': np.mean(loss_val_folds, axis=0)\n",
    "        } # média das curvas entre os 10 folds para suavizar a curva\n",
    "\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuracia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'CNN', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b6829",
   "metadata": {},
   "source": [
    "### Rodando a KNN\n",
    "\n",
    "**Avaliação do KNN**: define-se a lista **k_values** contendo os hiperparâmetros de vizinhos a serem testados, variando de 1 a 20, conforme estipulado no artigo para comparação com as redes neurais. O loop itera sobre cada valor **k** para realizar a validação cruzada.\n",
    "\n",
    "**Loop de Validação Cruzada**: utiliza-se novamente o objeto **skf.split()** para garantir que os folds sejam idênticos aos experimentos anteriores. Uma distinção importante ocorre aqui: enquanto as redes neurais utilizavam rótulos one-hot encoded, o KNN utiliza os vetores de rótulos inteiros. Portanto, as variáveis de alvo **y_fold_train_labels** e **y_fold_val_labels** são extraídas diretamente de **y_train_int** (formato original 0-7) com base nos índices do fold atual.\n",
    "\n",
    "**Construção e Treinamento**: para cada fold, instancia-se o classificador **KNeighborsClassifier** configurado com o número de vizinhos **n_neighbors=k** da iteração atual. O método **knn.fit()** é chamado para ajustar o modelo aos dados de treino do fold. Diferente das redes neurais que requerem múltiplas épocas, o KNN é um algoritmo de aprendizado preguiçoso (*lazy learning*), onde o \"treinamento\" consiste basicamente no armazenamento dos dados para cálculos de distância posteriores.\n",
    "\n",
    "**Coleta de Métricas e Agregação**: a avaliação é feita através de **knn.score()**, que retorna diretamente a acurácia do modelo nos dados de validação. Esse valor é acumulado na lista **rel_acuraacia**. Ao final dos 10 folds, calculam-se a média (**mean_acc**) e o desvio padrão (**std_acc**). O dicionário de resultados é atualizado com o identificador 'KNN', o valor de K testado e as métricas estatísticas consolidadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01186c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "k_values = [1, 2, 5, 10, 20]\n",
    "print(\"\\nAvaliando KNN...\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    tf.keras.backend.clear_session()\n",
    "    rel_acuracia = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train_labels = y_train_int[train_idx]\n",
    "        y_fold_val_labels = y_train_int[val_idx]\n",
    "        knn.fit(X_fold_train, y_fold_train_labels)\n",
    "        acc = knn.score(X_fold_val, y_fold_val_labels)\n",
    "        rel_acuracia.append(acc)\n",
    "    \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'KNN', 'Config': f'K={k}', 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2e88b",
   "metadata": {},
   "source": [
    "### Comparando Arquiteturas\n",
    "\n",
    "**Seleção dos Melhores Modelos**: Primeiramente, converte-se a lista de resultados da validação cruzada no DataFrame **resultados_df**. Utiliza-se o método **.groupby('Model')** para segregar os dados por tipo de algoritmo ('MLP', 'CNN', 'KNN') e o método **.idxmax()** na coluna **'Val_Acc_Mean'** para localizar o índice da configuração com melhor desempenho médio. O subset contendo apenas os campeões de cada categoria é armazenado em **melhores_por_tipo**.\n",
    "\n",
    "**Retreinamento e Teste Final**: Inicia-se um loop sobre os modelos vencedores. Nesta fase, a validação cruzada é substituída pelo treinamento definitivo para maximizar o aprendizado:\n",
    "* **Instanciação**: O modelo é reconstruído do zero com a configuração vencedora (**config**).\n",
    "* **Treinamento (Fit)**: Executa-se o **.fit()** utilizando **todo o conjunto de treino** (**X_train** e **y_train**), sem a divisão em folds.\n",
    "    * *Nota*: Para a CNN, utilizam-se os dados formatados com a dimensão extra de canal (**X_train_cnn**).\n",
    "* **Avaliação**: A performance real é medida no conjunto de teste separado (**X_test** ou **X_test_cnn**), dados que o modelo nunca viu anteriormente.\n",
    "\n",
    "**Processamento de Predições**:\n",
    "* **MLP e CNN**: Como as saídas são vetores de probabilidade (Softmax), utiliza-se **.predict()** seguido de **np.argmax(axis=1)** para converter as probabilidades na classe prevista (**y_pred**). O vetor de classes reais (**y_true**) é obtido de forma análoga a partir de **y_test** (one-hot encoded).\n",
    "* **KNN**: O parâmetro **k** é extraído da string de configuração. O método **.predict()** retorna diretamente as classes, e **y_true** é definido diretamente por **y_test_int**.\n",
    "\n",
    "**Cálculo Detalhado de Métricas (Macro)**:\n",
    "Para cada modelo, gera-se a **matriz de confusão** (**cm**). Em seguida, itera-se sobre a dimensão da matriz para calcular manualmente as métricas por classe, derivando os Verdadeiros Positivos (TP), Falsos Positivos (FP) e Falsos Negativos (FN). Com base nesses valores, calculam-se:\n",
    "1.  **Precisão, Recall e F1-Score** individuais por classe.\n",
    "2.  As médias **Macro** (média aritmética simples das métricas de todas as classes), armazenadas no dicionário **metricas_modelos**.\n",
    "\n",
    "**Visualização dos Resultados**:\n",
    "1.  **Mapas de Calor**: Para cada modelo, a matriz de confusão é plotada utilizando **sns.heatmap** e salva como imagem PNG no diretório `./images/`, facilitando a análise visual de erros entre classes específicas.\n",
    "2.  **Tabela Final Estilizada**:\n",
    "    * Cria-se um DataFrame **df_metricas** consolidando Acurácia, Precisão, Recall e F1-Score.\n",
    "    * Utiliza-se o **matplotlib** para desenhar uma tabela gráfica (não apenas textual).\n",
    "    * A tabela aplica formatação condicional de cores (**CORES**) para distinguir visualmente as linhas de MLP (Azul Escuro), CNN (Azul Médio) e KNN (Azul Claro).\n",
    "    * O resultado visual é salvo como **analise_melhores_modelos.png**, servindo como o resumo executivo comparativo do estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1049c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado Final\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# índice de melhor modelo para cada tipo de modelo\n",
    "idx_melhores = resultados_df.groupby('Model')['Val_Acc_Mean'].idxmax()\n",
    "melhores_por_tipo = resultados_df.loc[idx_melhores]\n",
    "\n",
    "#print(\"\\n\" + \"=\"*40)\n",
    "#print(\"MELHORES POR TIPO\")\n",
    "#print(\"=\"*40)\n",
    "\n",
    "matrizes_confusao = {}\n",
    "metricas_modelos = []\n",
    "\n",
    "# treinando cada melhor modelo de novo e depois testando com o conjunto de teste\n",
    "for _, row in melhores_por_tipo.iterrows():\n",
    "    tipo_modelo = row['Model']\n",
    "    config = row['Config']\n",
    "    final_acc = 0\n",
    "\n",
    "    if tipo_modelo == 'MLP':\n",
    "        mlp_final = constroi_mlp(config, mlp_shape, n_classes)\n",
    "        mlp_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        mlp_final.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        loss, final_acc = mlp_final.evaluate(X_test, y_test, verbose=0)\n",
    "        y_pred_probs = mlp_final.predict(X_test) # saída da CNN, é o vetor de probabilidades gerado pela função softmax\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1) # pega a maior probabilidade da saída e me retorna a posição dela, ou seja, qual classe o modelo preveu\n",
    "        y_true = np.argmax(y_test, axis=1) # é a classe verdadeira do dado, retorno a posição de onde está o bit 1, pois está em one hot encoded \n",
    "        \n",
    "    elif tipo_modelo == 'CNN':\n",
    "        modelo_final = constroi_cnn(config, cnn_shape, n_classes)\n",
    "        modelo_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        modelo_final.fit(X_train_cnn, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        loss, final_acc = modelo_final.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "        y_pred_probs = modelo_final.predict(X_test_cnn)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1) \n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "    elif tipo_modelo == 'KNN':\n",
    "        k = int(config.split('=')[1])\n",
    "        modelo_final = KNeighborsClassifier(n_neighbors=k)\n",
    "        modelo_final.fit(X_train, y_train_int)\n",
    "        final_acc = modelo_final.score(X_test, y_test_int)\n",
    "        y_pred = modelo_final.predict(X_test)\n",
    "        y_true = y_test_int\n",
    "\n",
    "    # geração da matriz de confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    matrizes_confusao[tipo_modelo] = cm\n",
    "\n",
    "    # cálculo das medidas da matriz\n",
    "    n_classes_cm = cm.shape[0]\n",
    "    precisao_por_classe = []\n",
    "    recall_por_classe = []\n",
    "    f1_por_classe = []\n",
    "    \n",
    "    for i in range(n_classes_cm):\n",
    "        tp = cm[i, i]\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        \n",
    "        precisao = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        precisao_por_classe.append(precisao)\n",
    "        \n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        recall_por_classe.append(recall)\n",
    "        \n",
    "        f1 = 2 * (precisao * recall) / (precisao + recall) if (precisao + recall) > 0 else 0\n",
    "        f1_por_classe.append(f1)\n",
    "    \n",
    "    precisao_macro = np.mean(precisao_por_classe)\n",
    "    recall_macro = np.mean(recall_por_classe)\n",
    "    f1_macro = np.mean(f1_por_classe)\n",
    "    \n",
    "    acuracia = np.trace(cm) / np.sum(cm)\n",
    "    \n",
    "    metricas_modelos.append({\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Configuracao': config,\n",
    "        'Acuracia': acuracia,\n",
    "        'Precisao_Macro': precisao_macro,\n",
    "        'Recall_Macro': recall_macro,\n",
    "        'F1_Macro': f1_macro\n",
    "    })\n",
    "\n",
    "    # plotando matriz de confusão com mapa de calor\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    print(f\"Matriz de Confusão para {tipo_modelo}:\")\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', \n",
    "                xticklabels=nomes_classes, yticklabels=nomes_classes)\n",
    "    plt.xlabel('Previsão', fontsize=12)\n",
    "    plt.ylabel('Realidade', fontsize=12)\n",
    "    plt.title(f'Matriz de Confusão de {tipo_modelo} - versão {config}', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    nome_saida = \"./images/matriz_confusao_\" + tipo_modelo + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    #plt.show()\n",
    "\n",
    "    #print(f\"-> Acurácia Final ({tipo_modelo}): {final_acc:.4f}\\n\")\n",
    "\n",
    "# melhores modelos\n",
    "df_metricas = pd.DataFrame(metricas_modelos)\n",
    "\n",
    "print(df_metricas.to_string(index=False))\n",
    "\n",
    "df_metricas_formatado = df_metricas.copy()\n",
    "df_metricas_formatado['Acuracia'] = df_metricas_formatado['Acuracia'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['Precisao_Macro'] = df_metricas_formatado['Precisao_Macro'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['Recall_Macro'] = df_metricas_formatado['Recall_Macro'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['F1_Macro'] = df_metricas_formatado['F1_Macro'].map('{:.4f}'.format)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "dados_tabela = df_metricas_formatado.values\n",
    "cabecalhos = [\"Modelo\", \"Configuração\", \"Acurácia\", \"Precisão\\n(Macro)\", \"Recall\\n(Macro)\", \"F1-Score\\n(Macro)\"]\n",
    "\n",
    "table = ax.table(cellText=dados_tabela,\n",
    "                 colLabels=cabecalhos,\n",
    "                 loc='center',\n",
    "                 cellLoc='center',\n",
    "                 colWidths=[0.12, 0.18, 0.15, 0.18, 0.18, 0.19])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "CORES = {\n",
    "    \"MLP\": \"#001C53\", \n",
    "    \"CNN\": \"#008CFF\",  \n",
    "    \"KNN\": \"#74ADFC\"   \n",
    "}\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('white')\n",
    "    cell.set_linewidth(1.5)\n",
    "    \n",
    "    if row == 0:\n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "        cell.set_facecolor('#333333')\n",
    "        cell.set_height(0.08)\n",
    "    else:\n",
    "        idx_real = row - 1\n",
    "        modelo = df_metricas_formatado.iloc[idx_real][\"Modelo\"]\n",
    "        \n",
    "        if col == 0:\n",
    "            cor_fundo = CORES.get(modelo, \"#cccccc\")\n",
    "            cell.set_facecolor(cor_fundo)\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            if row % 2 == 0:\n",
    "                cell.set_facecolor('#f2f2f2')\n",
    "            else:\n",
    "                cell.set_facecolor('#ffffff')\n",
    "            cell.set_text_props(color='#333333')\n",
    "\n",
    "plt.suptitle('Análise de Desempenho dos Melhores Modelos', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "nome_saida = \"./images/analise_melhores_modelos.png\"\n",
    "plt.savefig(nome_saida, dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2979da",
   "metadata": {},
   "source": [
    "### Geração da Matriz de Confusão Combinada\n",
    "\n",
    "**Unificação dos Resultados**: Para facilitar a comparação direta entre as três arquiteturas em uma única visualização, o código gera uma matriz combinada. Inicialmente, verifica-se a integridade do dicionário **matrizes_confusao**. Sendo validadas as chaves, extraem-se as matrizes de cada modelo ('MLP', 'CNN', 'KNN'). Um detalhe crucial é a **transposição (.T)** dessas matrizes: isso inverte os eixos padrão do *sklearn*, fazendo com que as **linhas representem as Classes Previstas** e as **colunas as Classes Reais**, facilitando a leitura da tabela final.\n",
    "\n",
    "**Formatação dos Dados**: Cria-se uma matriz vazia de objetos (**matriz_combinada**) de dimensão 8x8. Um loop duplo percorre cada posição $(i, j)$ para construir uma string composta no formato **\"ValorMLP / ValorCNN / ValorKNN\"**. Isso permite visualizar, em uma única célula, quantos acertos ou erros cada um dos três modelos teve para aquele par específico de classe Real vs. Prevista. Esses dados são encapsulados em um DataFrame do pandas (**df_combinado**) com rótulos abreviados ('N', 'C', 'D'...) para melhor ajuste visual.\n",
    "\n",
    "**Renderização da Tabela Gráfica**: Utiliza-se o **matplotlib** para desenhar o DataFrame como uma figura, ocultando os eixos cartesianos padrão (**ax.axis('off')**). A tabela é gerada via **ax.table()**, centralizando o conteúdo. O aspecto visual é refinado através de um loop que itera sobre as propriedades de cada célula (**table.get_celld()**), aplicando regras de estilização condicional:\n",
    "\n",
    "* **Cabeçalhos e Índices**: As células da primeira linha (títulos das colunas) e da primeira \"coluna virtual\" (índices das linhas) recebem fundo azul escuro (**#001C53**) e texto branco em negrito, mantendo a identidade visual do projeto.\n",
    "* **Diagonal Principal (Acertos)**: Identificadas pela lógica `row == col + 1` (ajuste necessário devido ao cabeçalho), essas células recebem fundo verde claro (**#d5ffb2**), destacando onde os modelos acertaram a predição.\n",
    "* **Erros (Fora da Diagonal)**: Caso o conteúdo da célula seja diferente de \"0/0/0\" (indicando que pelo menos um modelo confundiu aquelas classes), o fundo é pintado de vermelho claro (**#fad0d0**) para alertar sobre a confusão. Células vazias permanecem brancas para limpar o visual.\n",
    "\n",
    "**Exportação**: A visualização final, rica em informações comparativas, é salva em alta resolução (600 DPI) no arquivo **\"./images/matriz_confusao_COMBINADA.png\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906385aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da matriz de confusão combinada \n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Matriz de Confusão Combinada\")\n",
    "print(\"=\"*40)\n",
    "if all(k in matrizes_confusao for k in ['MLP', 'CNN', 'KNN']):\n",
    "    cm_mlp = matrizes_confusao['MLP'].T\n",
    "    cm_cnn = matrizes_confusao['CNN'].T\n",
    "    cm_knn = matrizes_confusao['KNN'].T\n",
    "\n",
    "    matriz_combinada = np.empty((8, 8), dtype=object)\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            matriz_combinada[i, j] = f\"{cm_mlp[i,j]}/{cm_cnn[i,j]}/{cm_knn[i,j]}\"\n",
    "\n",
    "    labels_colunas = ['N', 'C', 'D', 'F', 'CD', 'CF', 'DF', 'CDF']\n",
    "    labels_linhas = [f'Prev {l}' for l in labels_colunas]\n",
    "\n",
    "    df_combinado = pd.DataFrame(matriz_combinada, index=labels_linhas, columns=labels_colunas)\n",
    "    #print(df_combinado)\n",
    "else: \n",
    "    print(\"Falha ao gerar matriz de confusão combinada.\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8)) \n",
    "\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "table = ax.table(cellText=df_combinado.values,\n",
    "                 colLabels=df_combinado.columns,\n",
    "                 rowLabels=df_combinado.index,\n",
    "                 loc='center',\n",
    "                 cellLoc='center',\n",
    "                 bbox=[0, 0, 1, 1])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11) \n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('black')\n",
    "    cell.set_linewidth(1)\n",
    "    \n",
    "    \n",
    "    if row == 0:\n",
    "        cell.set_facecolor(\"#001C53\") \n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "    \n",
    "    elif col == -1: \n",
    "        cell.set_facecolor(\"#001C53\") \n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "    \n",
    "    else:\n",
    "        if row == col + 1:\n",
    "            cell.set_facecolor(\"#d5ffb2\") \n",
    "            cell.set_text_props(weight='bold', color='black')\n",
    "        else:\n",
    "            texto = cell.get_text().get_text() \n",
    "            if texto != \"0/0/0\":\n",
    "                cell.set_facecolor(\"#fad0d0\") \n",
    "            else:\n",
    "                cell.set_facecolor('white') \n",
    "\n",
    "nome_saida_combinada = \"./images/matriz_confusao_COMBINADA.png\"\n",
    "plt.savefig(nome_saida_combinada, dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb4567",
   "metadata": {},
   "source": [
    "### Geração de Relatórios Visuais da Validação Cruzada\n",
    "\n",
    "**Preparação e Formatação dos Dados**: Para transformar os resultados brutos em um relatório apresentável, cria-se um novo DataFrame (**df**) contendo apenas as colunas essenciais: Modelo, Configuração, Acurácia Média e Desvio Padrão. Os dados são ordenados de forma decrescente pela acurácia, garantindo que os melhores modelos apareçam no topo. Aplica-se uma formatação de string (**'{:.5f}'**) às colunas numéricas para padronizar a exibição com 5 casas decimais. Adicionalmente, mapeia-se uma coluna de **Cor** baseada no tipo de modelo (MLP, CNN, KNN) utilizando o dicionário **CORES**, que define a identidade visual do projeto.\n",
    "\n",
    "**Função de Renderização de Tabelas**: Define-se a função **gerar_tabela()**, que utiliza a biblioteca **Matplotlib** para converter o DataFrame em uma imagem estática de alta resolução. O processo envolve:\n",
    "1.  **Estrutura**: Criação de uma figura sem eixos (**ax.axis('off')**) e inserção dos dados via **ax.table()**.\n",
    "2.  **Estilização Condicional**: Um loop percorre cada célula da tabela para aplicar estilos específicos:\n",
    "    * **Cabeçalho (Linha 0)**: Recebe fundo cinza escuro (**#333333**) e texto branco em negrito.\n",
    "    * **Coluna de Acurácia (Coluna 2)**: Sendo a métrica principal, esta coluna recebe destaque especial. O fundo da célula é preenchido com a cor específica do modelo (Azul Escuro para MLP, Azul Médio para CNN, etc.), facilitando a identificação visual rápida da categoria do modelo.\n",
    "    * **Demais Células**: Aplica-se um efeito de \"zebra\" (alternância de cores entre branco e cinza claro **#f2f2f2**) para melhorar a legibilidade das linhas.\n",
    "\n",
    "**Segmentação e Exportação**: O script executa a função três vezes para gerar relatórios com diferentes níveis de granularidade, salvando-os no diretório **./images/**:\n",
    "1.  **Geral**: Uma tabela completa (**tabela_desempenhos_geral.png**) contendo todos os modelos testados, permitindo uma comparação global.\n",
    "2.  **Específico MLP**: Filtra-se o DataFrame original para isolar apenas as configurações de MLP, gerando um ranking exclusivo para essa arquitetura (**tabela_desempenhos_MLP.png**).\n",
    "3.  **Específico CNN**: Processo análogo para as Redes Neurais Convolucionais (**tabela_desempenhos_CNN.png**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração de tabela para resultados da validação cruzada\n",
    "#print(\"\\nResumo Completo da Validação Cruzada:\")\n",
    "#print(resultados_df[['Model', 'Config', 'Val_Acc_Mean', 'Val_Acc_Std']].sort_values(by='Val_Acc_Mean', ascending=False))\n",
    "\n",
    "# preparação dos dados\n",
    "df = pd.DataFrame({\n",
    "    \"Modelo\": resultados_df['Model'],\n",
    "    \"Configuracao\": resultados_df['Config'],\n",
    "    \"Media_Acuracia\": resultados_df['Val_Acc_Mean'],\n",
    "    \"Media_DP\": resultados_df['Val_Acc_Std'],\n",
    "})\n",
    "df = df.sort_values(by='Media_Acuracia', ascending=False)\n",
    "df['Media_Acuracia'] = df['Media_Acuracia'].map('{:.5f}'.format)\n",
    "df['Media_DP'] = df['Media_DP'].map('{:.5f}'.format)\n",
    "\n",
    "CORES = {\n",
    "    \"MLP\": \"#001C53\", \n",
    "    \"CNN\": \"#008CFF\",  \n",
    "    \"KNN\": \"#74ADFC\"   \n",
    "}\n",
    "df[\"Cor\"] = df[\"Modelo\"].map(CORES)\n",
    "\n",
    "# fazendo tabelas\n",
    "def gerar_tabela(df_filtrado, nome_arquivo, titulo_modelo=\"\"):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 14)) \n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    dados_tabela = df_filtrado[[\"Modelo\", \"Configuracao\", \"Media_Acuracia\", \"Media_DP\"]].values\n",
    "    cabecalhos = [\"Modelo\", \"Configuração\", \"Acurácia Média\", \"Desvio-Padrão Médio\"]\n",
    "    \n",
    "    table = ax.table(cellText=dados_tabela,\n",
    "                     colLabels=cabecalhos,\n",
    "                     loc='center',\n",
    "                     cellLoc='center',\n",
    "                     colWidths=[0.15, 0.20, 0.30, 0.35])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2.0) \n",
    "    \n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('white')\n",
    "        cell.set_linewidth(1.5)\n",
    "        \n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight='bold', color='white', size=14)\n",
    "            cell.set_facecolor('#333333')\n",
    "            cell.set_height(0.06)\n",
    "        \n",
    "        else:\n",
    "            idx_real = row - 1\n",
    "            com_id = df_filtrado.iloc[idx_real][\"Modelo\"] \n",
    "            \n",
    "            if col == 2:\n",
    "                cor_fundo = CORES.get(com_id, \"#cccccc\")\n",
    "                cell.set_facecolor(cor_fundo)\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            \n",
    "            else:\n",
    "                if row % 2 == 0:\n",
    "                    cell.set_facecolor('#f2f2f2')\n",
    "                else:\n",
    "                    cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='#333333')\n",
    "    \n",
    "    nome_saida = f\"./images/{nome_arquivo}\"\n",
    "    plt.savefig(nome_saida, dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# gerando tabelas\n",
    "gerar_tabela(df, \"tabela_desempenhos_geral.png\")\n",
    "\n",
    "df_mlp = df[df[\"Modelo\"] == \"MLP\"].copy()\n",
    "df_mlp = df_mlp.sort_values(by='Media_Acuracia', ascending=False).reset_index(drop=True)\n",
    "gerar_tabela(df_mlp, \"tabela_desempenhos_MLP.png\", \"MLP\")\n",
    "\n",
    "df_cnn = df[df[\"Modelo\"] == \"CNN\"].copy()\n",
    "df_cnn = df_cnn.sort_values(by='Media_Acuracia', ascending=False).reset_index(drop=True)\n",
    "gerar_tabela(df_cnn, \"tabela_desempenhos_CNN.png\", \"CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0878e",
   "metadata": {},
   "source": [
    "### Visualização das Curvas de Aprendizado\n",
    "\n",
    "**Definição da Função de Plotagem**: define-se a função **plotar_curvas_loss()** que recebe como argumentos o dicionário de históricos acumulados (**historico**) e a chave do tipo de modelo a ser visualizado (**tipo_modelo**, ex: 'MLP' ou 'CNN'). O objetivo é gerar gráficos comparativos que permitam analisar a convergência e o ajuste dos modelos ao longo das épocas.\n",
    "\n",
    "**Configuração da Figura**: utiliza-se **plt.subplots(1, 2)** para criar uma figura contendo dois gráficos lado a lado: o primeiro (**ax1**) dedicado aos dados de treino e o segundo (**ax2**) aos dados de validação. As dimensões da figura são fixadas em 18x6 polegadas para garantir legibilidade. A variável **epochs** define o eixo X, representando o intervalo de épocas percorrido durante o treinamento.\n",
    "\n",
    "**Plotagem das Curvas de Treino**: itera-se sobre cada configuração (**cfg**) e suas respectivas métricas armazenadas no dicionário. No eixo **ax1**, plota-se a curva de perda média de treinamento (**curvas['train']**). Adicionam-se elementos visuais essenciais: título ('Função de Perda no treino'), rótulos dos eixos, legenda para identificar cada configuração ('4N', 'M1', etc.) e grade (**grid**) para facilitar a leitura dos valores.\n",
    "\n",
    "**Plotagem das Curvas de Validação**: repete-se a lógica de iteração para o eixo **ax2**, porém plotando a curva de perda média de validação (**curvas['val']**). Este gráfico é crucial para identificar comportamentos de *overfitting* (quando a perda de validação começa a subir enquanto a de treino cai) ou a estabilidade das diferentes arquiteturas em dados não vistos.\n",
    "\n",
    "**Execução**: por fim, a função é chamada explicitamente para os dois grupos de modelos, **'MLP'** e **'CNN'**, gerando as visualizações que permitem comparar qual topologia convergiu mais rápido e qual atingiu o menor erro final, replicando a análise visual apresentada na Figura 3 do artigo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando gráfico da função de perda a cada época no treinamento das MLP e CNN\n",
    "\n",
    "def plotar_curvas_loss(historico, tipo_modelo):\n",
    "    # treino\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    epochs = range(1, EPOCHS + 1)\n",
    "    \n",
    "    for cfg, curvas in historico[tipo_modelo].items():\n",
    "        ax1.plot(epochs, curvas['train'], label=f'{cfg}')\n",
    "    \n",
    "    ax1.set_title(f'Função de Perda no treino', fontsize=14)\n",
    "    ax1.set_xlabel('Épocas')\n",
    "    ax1.set_ylabel('Perda')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # validação\n",
    "    for cfg, curvas in historico[tipo_modelo].items():\n",
    "        ax2.plot(epochs, curvas['val'], label=f'{cfg}')\n",
    "    \n",
    "    ax2.set_title(f'Função de Perda na validação', fontsize=14)\n",
    "    ax2.set_xlabel('Épocas')\n",
    "    ax2.set_ylabel('Perda')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    nome_saida = \"./images/grafico_loss_curves\" + tipo_modelo + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "plotar_curvas_loss(historico_perdas, 'MLP')\n",
    "plotar_curvas_loss(historico_perdas, 'CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb82e5",
   "metadata": {},
   "source": [
    "### Análise de Componentes Principais (PCA)\n",
    "\n",
    "**Definição da Função de Plotagem**: implementa-se a função **gerar_pca()** para encapsular a lógica de redução de dimensionalidade e visualização. A função inicializa o objeto **PCA** com **n_components=2**, reduzindo as 201 dimensões originais (features de pressão) para apenas 2 componentes principais, permitindo a plotagem em um plano cartesiano.\n",
    "\n",
    "**Estruturação dos Dados**: o método **fit_transform()** é aplicado aos dados de entrada para calcular os autovetores e projetar os dados no novo espaço reduzido. O resultado é organizado em um DataFrame do pandas contendo as colunas 'PCA1' e 'PCA2', além da coluna 'Classe' com os rótulos verdadeiros (**true_labels**), o que facilita o agrupamento visual.\n",
    "\n",
    "**Visualização por Dispersão**: utiliza-se um loop para iterar sobre cada classe única, plotando os pontos correspondentes via **plt.scatter()**. Isso garante que cada tipo de falha seja representado por uma cor distinta e associada ao seu nome legível (via lista **nomes_classes**). O gráfico é finalizado com rótulos de eixos, título personalizado, legenda e grade.\n",
    "\n",
    "**Visualização dos Dados Brutos (Baseline)**: a primeira chamada da função é feita passando o conjunto de teste original (**X_test**) e os rótulos inteiros (**y_test_int**). Este gráfico serve como linha de base, mostrando como as classes estão distribuídas naturalmente no espaço de entrada antes de qualquer processamento pela rede neural, correspondendo à parte superior da Figura 4 do artigo.\n",
    "\n",
    "**Extração de Características (Hidden Layer)**: para visualizar o aprendizado da rede e contornar limitações de acesso ao grafo do modelo Sequential, reconstrói-se o fluxo de dados manualmente via API Funcional. Define-se um novo tensor de entrada (**tf.keras.Input**) e itera-se sobre as camadas já treinadas do MLP (**mlp_final.layers[:-1]**), aplicando-as sequencialmente até a penúltima camada. Um novo modelo extrator (**saida_oculta**) é instanciado conectando essa nova entrada à saída processada, isolando as representações internas (features) antes da classificação Softmax.\n",
    "\n",
    "**Visualização das Representações Latentes**: os dados de teste são passados por esse modelo reconstruído (**saida_oculta.predict**), gerando o conjunto **X_saida_oculta**. A função **gerar_pca()** é chamada novamente com esses novos dados. O gráfico resultante demonstra a capacidade da rede neural de transformar o espaço de dados, agrupando classes que antes estavam sobrepostas e facilitando a classificação linear final, correspondendo à parte inferior da Figura 4 do artigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração do PCA para visualização da separação das classes usando o melhor MLP\n",
    "\n",
    "def gerar_pca(dados, true_labels, titulo, nome_img):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(dados)\n",
    "\n",
    "    df = pd.DataFrame(data=X_pca, columns=['PCA1','PCA2'])\n",
    "    df['Classe'] = true_labels\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    for classe in sorted(df['Classe'].unique()):\n",
    "        subset = df[df['Classe'] == classe]\n",
    "        plt.scatter(\n",
    "            subset['PCA2'],\n",
    "            subset['PCA1'],\n",
    "            label=nomes_classes[classe],\n",
    "            alpha=0.6,\n",
    "            marker='o'\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('PCA2', fontsize=12)\n",
    "    plt.ylabel('PCA1', fontsize=12)\n",
    "    plt.title(titulo, fontsize=14)\n",
    "    plt.legend(title='Classe', markerscale=1.5, fontsize=8)\n",
    "    plt.grid(True)\n",
    "    nome_saida = \"./images/PCA\" + nome_img + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "gerar_pca(dados=X_test, true_labels=y_test_int, titulo='Decomposição dos Inputs antes Camada Oculta (PCA)', nome_img='_pre_camada_oculta')\n",
    "\n",
    "# Visualizar após a camada oculta nome_img='_pos_camada_oculta'\n",
    "input_tensor = tf.keras.Input(shape=(n_features,))\n",
    "\n",
    "x = input_tensor\n",
    "for layer in mlp_final.layers[:-1]:\n",
    "    x = layer(x)\n",
    "\n",
    "saida_oculta = tf.keras.models.Model(\n",
    "    inputs=input_tensor,\n",
    "    outputs=x\n",
    ")\n",
    "\n",
    "X_saida_oculta = saida_oculta.predict(X_test)\n",
    "\n",
    "gerar_pca(dados=X_saida_oculta, true_labels=y_test_int, titulo='Decomposição dos Inputs após Camada Oculta (PCA)', nome_img='_pos_camada_oculta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabalho_neural_networks",
   "language": "python",
   "name": "neural_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
