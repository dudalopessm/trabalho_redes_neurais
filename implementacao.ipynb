{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e2a7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5157e0a",
   "metadata": {},
   "source": [
    "Definição das constantes - caminho do dataset e nomes das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2307e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARQUIVOS\n",
    "ATTRIBUTES_FILE = './dataset/attributes.csv'\n",
    "LABELS_FILE = './dataset/label.csv'\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: 'Normal',\n",
    "    1: 'Charge',\n",
    "    2: 'Discharge',\n",
    "    3: 'Friction',\n",
    "    4: 'Charge Discharge',\n",
    "    5: 'Charge Friction',\n",
    "    6: 'Discharge Friction',\n",
    "    7: 'Charge Discharge Friction'\n",
    "}\n",
    "\n",
    "nomes_classes = list(CLASS_NAMES.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2c8e8",
   "metadata": {},
   "source": [
    "Os números gerados aleatoriamente pelo computador na verdade são pseudo-aleatórios. Assim, setar uma random seed constante faz com que os pesos iniciais, que são gerados aleatoriamente primeiro, sejam sempre iniciados com o mesmo valor aleatório. Para isso, travamos a aleatoriedade do numPy e do TensorFlow com .seed e set_seed. Isso trava os resultados da rede neural em sempre uma mesma acurácia.\n",
    "\n",
    "42 é só um número atoa, ele na verdade vem da resposta para a Questão Fundamental da Vida, do Universo e Tudo Mais - O Guia do Mochileiro das Galáxias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f87d70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para os dados aleatorios se repetirem\n",
    "np.random.seed(24)\n",
    "tf.random.set_seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ea797",
   "metadata": {},
   "source": [
    "### carrega_dados\n",
    "\n",
    "**X.shape[0]**: número de linhas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de amostras disponíveis.\n",
    "\n",
    "**X.shape[1]**: número de colunas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de colunas do csv de amostras. ou seja, quantas variações de tempo uma única amostra possui. \n",
    "\n",
    "**X**: \n",
    "| Amostra | feature_1 | feature_2 | ... | feature_201  |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| amostra 1 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 2 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 3 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "|  ...      |       ...        |         ...      | ... |           ...      |\n",
    "\n",
    "**tf.keras.utils.to_categorical(y, num_classes=num_classes)**: converte rótulos de classes inteiros para formato one-hot encoded. é armazenado em uma array numPy. seu tamanho é linhas_amostras x nro_classes. \n",
    "\n",
    "**y_categorical**:\n",
    "| Amostra | Neurônio 1 (Normal) | Neurônio 2 (Charge) | ... | Neurônio 8 (All Faults) |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| Linha 1 | 1 | 0 | ... | 0 |\n",
    "| Linha 2 | 0 | 0 | ... | 1 |\n",
    "| Linha 3 | 0 | 0 | ... | 0 |\n",
    "|  ...    | 0 | 0 | ... | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a7315d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(attr_caminho, lbl_caminho):\n",
    "\n",
    "    print(f\"Lendo atributos: {attr_caminho}\")\n",
    "    print(f\"Lendo labels: {lbl_caminho}\")\n",
    "    \n",
    "    X_df = pd.read_csv(attr_caminho)\n",
    "    y_df = pd.read_csv(lbl_caminho)\n",
    "\n",
    "    # converte para vetor\n",
    "    X = X_df.values\n",
    "    y = y_df.values.flatten() \n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    print(f\"Dataset carregado com sucesso:\")\n",
    "    print(f\" - Amostras: {X.shape[0]}\")\n",
    "    print(f\" - Features (Timestamps): {num_features}\")\n",
    "    print(f\" - Classes únicas encontradas: {num_classes} {np.unique(y)}\")\n",
    "\n",
    "    # One-hot para redes neurais\n",
    "    y_categorical = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "    \n",
    "    return X, y_categorical, y, num_features, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc5f0c",
   "metadata": {},
   "source": [
    "### constroi_mlp\n",
    "\n",
    "Define as arquiteturas das MLP usadas no artigo. A função recebe o nome da configuração, a forma de entrada (timestamps do dataset) e número de classes de saída. \n",
    "\n",
    "**models.Sequential()**: cria um objeto do tipo modelo sequencial -> camadas da rede serão empilhadas uma após a outra em ordem. \n",
    "\n",
    "**model.add(layers.InputLayer(shape=shape))**: define camada de entrada com o formato de entrada dos dados. O argumento shape informa a rede o número de features que ela receberá.\n",
    "\n",
    "**estrutura do if**: o if definirá a camada oculta com base no nome da configuração. Se for X neurônios, model.add(layers.Dense(X, activation='relu')) adiciona uma camada densa com X neurônios e a função de ativação ReLU. A parte de 16-8N é uma topologia multi-camada, ou seja, há duas camadas ocultas: uma densa com 16 neurônios e outra densa com 8 neurônios, ambas com função de ativação ReLU. Por fim, a camada de saída é comum a todas as redes com o número de neurônios exatamente igual ao número de classes (8). A função de ativação dessa camada é a Softmax, que transforma os scores internos em probabilidades para cada classe.\n",
    "\n",
    "Por fim, a função *constroi_mlp()* retorna o objeto model (ou seja, retorna um modelo de aprendizado) completo e pronto para treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "517ae7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELOS (Tópico 3.4)\n",
    "\n",
    "def constroi_mlp(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == '4N':\n",
    "        model.add(layers.Dense(4, activation='relu'))\n",
    "    elif config_name == '8N':\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '16N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "    elif config_name == '32N':\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif config_name == '16-8N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '8-8-8N_autoral':\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '32N_autoral':\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif config_name == '16-16N_autoral':\n",
    "        model.add(layers.Dense(16, activation='sigmoid'))\n",
    "        model.add(layers.Dense(16, activation='sigmoid'))\n",
    "    elif config_name == 'worst_network':\n",
    "        model.add(layers.Dense(4, activation='relu'))\n",
    "        \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d600a6",
   "metadata": {},
   "source": [
    "### constroi_cnn\n",
    "\n",
    "A função define as arquiteturas das CNN usadas no artigo. Recebe o nome da configuração (Mx), o formato da entrada (no nosso caso, 201 timestamps de pressão do dataset) e o número de classes (8 no nosso caso).\n",
    "\n",
    "**models.Sequential()**: cria uma pilha linear de camadas em que os dados fluem sequencialmente de uma camada para outra.\n",
    "\n",
    "**model.add(layers.InputLayer(shape=shape))**: a rede receberá um vetor com a forma informada na função, ou seja, receberá um vetor de 201 pontos de pressão regulada conforme nosso dataset.\n",
    "\n",
    "**bloco if**: primeiramente seleciona a configuração base Mx. A base da M1 até a M4 é a seguinte, em que **A**, **B** e **C** são parâmetros fornecidos pelo artigo:\n",
    "```python\n",
    "if config == Mx, em que x = número de 1 a 4:\n",
    "    model.add(layers.Conv1D(filters=**A**, kernel_size=**B**, padding='same')) \n",
    "    # Adiciona camada de convolução 1D. Aplica **A** filtro(s) deslizante(s) com o tamanho de janela de **B** pontos temporais. Isso extrai características locais da curva de presão. \n",
    "    model.add(layers.AveragePooling1D(pool_size=**C**))\n",
    "    # Adiciona a camada de pooling reduzindo a dimensão dos dados tirando média a cada **C** pontos.\n",
    "    model.add(layers.Flatten())\n",
    "    # Adiciona camada de achatamento transformando a matriz resultante das convoluções em um vetor longo e único para entrar na camada densa\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    # Por fim, adiciona camada densa intermediária antes da fully-connected com processamento de 16 neurônios e ReLU de ativação, sendo um padrão em todas as CNNs testadas no artigo.\n",
    "    # A camada M5 possui um segundo bloco de camada de convolução 1D e pooling, ou seja, a rede é mais profunda. \n",
    "model.add(layers.Dense(num_classes, activation='softmax')) # Todas as camadas Mx, da 1 até a 5, recebem a última camada de saída com o número de neurônios = número de classes com ativação Softmax.\n",
    "```\n",
    "\n",
    "**Diferenças das configurações M1 até M5**:\n",
    "- M1: configuração base das CNNs testadas, com 1 filtro deslizante, tamanho de janela de 8 pontos temporais e redução de dimensão de dados a cada 4 pontos.\n",
    "- M2: os autores testaram se aumentar o número de filtros deslizantes de 1 para 2 melhora a detecção de características, com o resto igual a M1.\n",
    "- M3: o artigo testa se uma janela de observação maior de 16 pontos temporais captura melhores padrões, com o resto igual a M1.\n",
    "- M4: aumenta o número da redução da dimensão de dados de 4 para 8, com o resto igual a M1.\n",
    "- M5: adiciona segundo bloco de convolução 1D e pooling, testando se uma rede mais profunda com duas camadas de convolução melhora o desempenho.\n",
    "\n",
    "Por fim, a função retorna o modelo de aprendizado construído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0591fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constroi_cnn(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == 'M1':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M2':\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M3':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=16)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M4':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=8))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M5':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "     \n",
    "    elif config_name == 'M6_autoral': #Modelo M1 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M7_autoral': #Modelo M2 com tanh\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M8_autoral': #Modelo M3 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=16)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M9_autoral': #Modelo M4 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=8))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "        \n",
    "    elif config_name == 'M10_autoral': #Modelo M5 com tanh\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8)) \n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8))\n",
    "        model.add(layers.AveragePooling1D(pool_size=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='tanh'))\n",
    "\n",
    "    elif config_name == 'M11_autoral': #Modelo maior com tanh\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=16, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(32, activation='tanh'))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d65d9e",
   "metadata": {},
   "source": [
    "### Experimentação\n",
    "\n",
    "Primeiramente há o carregamento dos dados por meio da função carrega_dados() anteriormente discutida. Há o retorno das variáveis:\n",
    "- **X**: matriz com as 8000 amostras de pressão.\n",
    "- **y_cat**: rótulos das categorias de classificação no formato one-hot encoded.\n",
    "- **y_integers**: rótulos das categorias em formato original para usar na estratificação da validação cruzada.\n",
    "- **n_features**: número de momentos diferentes da mesma pressão, no caso, 201.\n",
    "- **n_classes**: quantas classes o problema de classificação possui.\n",
    "\n",
    "**Separação do dataset**: é por meio da função train_test_split(). A função recebe o dataset inteiro (**X**), os rótulos das categorias hot encoded (**y_cat**), os rótulos das categorias inteiros (**y_integers**), o tamanho do dataset de teste pretendido, nesse caso, 10% ou seja, **test_size = 0.10**. O dataset de teste nunca encontrará o dataset de treino, essa função garante que a informação testada nunca tenha sido reconhecida pelo modelo anteriormente. O atributo **stratify** da função garante a amostragem estratificada mantendo a mesma proporção de falhas tanto no treino quanto no teste. Ele recebe y_integers como valor, ou seja, identifica-se quantas classes devem ser garantidas na mesma porcentagem. O **random_state = 0.42** garante que a divisão seja sempre a mesma. Por fim, a função devolve o dataset de treino em **X_train**, o dataset de teste em **X_test**, as classes de treino em **y_train**, as classes de teste em **y_test** tanto em hot encoded quanto em inteiros (**y_train_int** e **y_test_int**).\n",
    "\n",
    "**Preparação de dados para a CNN**: as matrizes de dados **X_train** e **X_test** não estão no formato esperado pelas camadas convolucionais (Conv1D) da biblioteca Keras, que exigem uma entrada tridimensional (amostras, timesteps, canais). Por isso, utiliza-se a função reshape() para adicionar uma dimensão extra de tamanho 1 ao final, representando o único canal da série temporal. As novas variáveis **X_train_cnn** e **X_test_cnn** assumem o formato (amostras, 201, 1).\n",
    "\n",
    "**Definição dos formatos de entrada**: são criadas as tuplas **mlp_shape** e **cnn_shape** para informar à primeira camada de cada rede qual o formato dos dados que entrarão. Para o MLP é um vetor plano de (201,) e para a CNN é a estrutura de (201, 1).\n",
    "\n",
    "**Definição de Hiperparâmetros**: são estabelecidas as constantes que guiarão o processo de treinamento:\n",
    "- **EPOCHS** = 50: define que o modelo passará pelo dataset completo 50 vezes durante o treino.\n",
    "- **BATCH_SIZE** = 32: indica que os pesos da rede serão atualizados a cada 32 amostras processadas.\n",
    "- **K_FOLDS** = 10: define que a validação cruzada dividirá os dados de treino em 10 partes distintas.\n",
    "\n",
    "**Configuração da Validação Cruzada**: inicializa-se uma lista vazia resultados para armazenar as métricas de cada rodada. O objeto **skf** é instanciado usando a classe StratifiedKFold. Ele é configurado com **n_splits=10** (para dividir em 10 partes), **shuffle=True** (para embaralhar os dados antes da divisão e evitar viés de ordem) e **random_state=42** (para garantir a reprodutibilidade dos folds). Esse objeto não divide os dados imediatamente, mas define a lógica que será usada no loop de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTOS\n",
    "    \n",
    "X, y_cat, y_integers, n_features, n_classes = carrega_dados(ATTRIBUTES_FILE, LABELS_FILE)\n",
    "\n",
    "# divisao treino/teste (10% Teste)\n",
    "X_train, X_test, y_train, y_test, y_train_int, y_test_int = train_test_split(\n",
    "    X, y_cat, y_integers, test_size=0.10, stratify=y_integers, random_state=24\n",
    ")\n",
    "\n",
    "# CNN: (samples, timesteps, features=1)\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "mlp_shape = (n_features,)\n",
    "cnn_shape = (n_features, 1)\n",
    "\n",
    "EPOCHS = 50 \n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 10\n",
    "\n",
    "resultados = []\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=24)\n",
    "\n",
    "print(f\"\\nIniciando Validação Cruzada (K={K_FOLDS})...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72f20a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para guardar as médias de loss de cada configuração\n",
    "\n",
    "historico_perdas = {'MLP': {}, 'CNN': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fa893",
   "metadata": {},
   "source": [
    "### Rodando as arquiteturas MLP\n",
    "\n",
    "**Avaliação das topologias MLP**: define-se a lista **configuracoes_mlp** contendo as chaves das arquiteturas propostas no artigo, variando de '4N' até '16-8N'. O loop principal percorre cada configuração **cfg**. Assim como na etapa anterior, executa-se **tf.keras.backend.clear_session()** antes dos folds para garantir que a memória esteja limpa e evitar interferências entre treinamentos. Inicializam-se as listas **loss_train_folds** e **loss_val_folds** para acumular as curvas de perda de cada iteração.\n",
    "\n",
    "**Loop de Validação Cruzada**: utiliza-se o método **skf.split()** aplicado aos dados de treino (**X_train**) e seus rótulos inteiros (**y_train_int**). Esse método gera, para cada uma das 10 iterações (folds), os índices específicos de treino (**train_idx**) e validação (**val_idx**). Com base nesses índices, os dados são fatiados criando os subconjuntos de treino do fold (**X_fold_train**, **y_fold_train**) e os de validação do fold (**X_fold_val**, **y_fold_val**).\n",
    "\n",
    "**Construção e Treinamento com Monitoramento**: para cada fold, uma nova instância limpa do modelo é instanciada via **constroi_mlp()**, recebendo a configuração atual e o formato de entrada **mlp_shape**. O modelo é compilado definindo o otimizador como **adam** e a função de perda como **categorical_crossentropy**. O treinamento é executado via **model.fit()**, agora incluindo o parâmetro **validation_data=(X_fold_val, y_fold_val)** para registrar a perda de validação a cada época. Todo o processo de treinamento é salvo na variável **historico**.\n",
    "\n",
    "**Armazenamento das Curvas de Perda**: extraem-se os valores de perda (*loss* e *val_loss*) do objeto **historico** e eles são anexados às listas de controle. Após a conclusão dos 10 folds, calcula-se a média dessas curvas (**np.mean(..., axis=0)**) e armazena-se o resultado suavizado no dicionário **historico_perdas['MLP']**, permitindo a visualização posterior da convergência.\n",
    "\n",
    "**Coleta de Métricas e Agregação**: imediatamente após o treino, o modelo é submetido aos dados de validação através de **model.evaluate()**, e a acurácia obtida é armazenada na lista temporária **rel_acuracia**. Ao término dos 10 folds para uma configuração, calculam-se a média (**mean_acc**) e o desvio padrão (**std_acc**) das acurácias observadas. Esses valores consolidados são adicionados à lista **resultados**, registrando o tipo de modelo ('MLP'), a configuração testada e suas métricas de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "configuracoes_mlp = ['worst_network','32N_autoral', '4N', '8N', '16N', '32N', '16-8N', '8-8-8N_autoral', '16-16N_autoral']\n",
    "\n",
    "for cfg in configuracoes_mlp: \n",
    "    print(f\"Avaliando MLP: {cfg}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    rel_acuracia = []\n",
    "\n",
    "    loss_train_folds = [] # acumula curvas dos folds de treino\n",
    "    loss_val_folds = [] # acumula curvas dos folds de validation\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_mlp(cfg, mlp_shape, n_classes)\n",
    "\n",
    "        if(cfg=='32N_autoral'):\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "            reducao_taxa_aprendizado = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                         factor=0.2, \n",
    "                                                         patience=2, \n",
    "                                                         min_lr=1e-7) # patience = nro de epocas que a lr estará ativa\n",
    "\n",
    "            model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val),\n",
    "                callbacks=[reducao_taxa_aprendizado]\n",
    "            )\n",
    "        elif(cfg=='worst_network'):\n",
    "            opt = tf.keras.optimizers.SGD(learning_rate=0.2)\n",
    "            #reducao_taxa_aprendizado = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5)\n",
    "            model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val)\n",
    "            )\n",
    "        else:\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            history = model.fit(\n",
    "                X_fold_train, y_fold_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0,\n",
    "                validation_data=(X_fold_val, y_fold_val)\n",
    "            ) # acrescentado atributo validation_data para guardar cada dado de validação gerado no fit\n",
    "\n",
    "\n",
    "        loss_train_folds.append(history.history['loss'])\n",
    "        loss_val_folds.append(history.history['val_loss'])\n",
    "\n",
    "        historico_perdas['MLP'][cfg] = {\n",
    "            'train': np.mean(loss_train_folds, axis=0),\n",
    "            'val': np.mean(loss_val_folds, axis=0)\n",
    "        } # média das curvas entre os 10 folds para suavizar a curva\n",
    "\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuracia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'MLP', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b476bf2",
   "metadata": {},
   "source": [
    "### Rodando as arquiteturas CNN\n",
    "\n",
    "**Avaliação das topologias CNN**: estabelece-se a lista **configuracoes_cnn** com as variações de arquitetura descritas no estudo, indo de 'M1' a 'M5'. O loop principal percorre cada configuração **cfg**. Antes de iniciar os folds, executa-se **tf.keras.backend.clear_session()** para liberar a memória da GPU/CPU, evitando vazamento de estados entre modelos. Inicializam-se também as listas **loss_train_folds** e **loss_val_folds** para acumular o histórico de aprendizado.\n",
    "\n",
    "**Loop de Validação Cruzada**: repete-se a lógica de divisão utilizada anteriormente com o método **skf.split()**, garantindo que os mesmos índices de folds sejam usados, o que permite uma comparação justa entre MLP e CNN. A diferença crucial ocorre no fatiamento dos dados: as variáveis **X_fold_train** e **X_fold_val** são extraídas da matriz **X_train_cnn** (previamente redimensionada para 3 dimensões), enquanto os rótulos **y_fold_train** e **y_fold_val** continuam vindo do vetor original **y_train**.\n",
    "\n",
    "**Construção e Treinamento com Monitoramento**: a cada iteração do fold, o modelo é instanciado pela função **constroi_cnn()** e compilado com otimizador **adam** e perda **categorical_crossentropy**. O ajuste dos pesos via **model.fit()** recebe um argumento adicional crucial: **validation_data=(X_fold_val, y_fold_val)**. Isso força o modelo a calcular a perda nos dados de validação ao final de cada época, sem treinar neles. O objeto de retorno é capturado na variável **historico**.\n",
    "\n",
    "**Armazenamento das Curvas de Perda**: extraem-se os vetores de perda de treino e validação do objeto **historico**, acumulando-os nas listas temporárias. Ao fim de cada fold, armazena-se no dicionário global **historico_perdas['CNN']** a média aritmética dessas curvas (**np.mean(..., axis=0)**). Esse procedimento suaviza as oscilações naturais de cada fold individual, gerando uma curva representativa do comportamento daquela arquitetura.\n",
    "\n",
    "**Coleta de Métricas e Agregação**: o desempenho final do modelo no fold é medido através de **model.evaluate()**, salvando a acurácia na lista **rel_acuracia**. Ao final do ciclo de 10 folds, computam-se a média (**mean_acc**) e o desvio padrão (**std_acc**). Os dados são estruturados e anexados à lista geral **resultados**, permitindo a comparação direta de performance com os modelos MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "configuracoes_cnn = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6_autoral', 'M7_autoral', 'M8_autoral', 'M9_autoral', 'M10_autoral', 'M11_autoral']\n",
    "\n",
    "for cfg in configuracoes_cnn:\n",
    "    print(f\"Avaliando CNN: {cfg}\")\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    loss_train_folds = [] # acumula curvas dos folds de treino\n",
    "    loss_val_folds = [] # acumula curvas dos folds de validation\n",
    "\n",
    "    rel_acuracia = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train_cnn[train_idx], X_train_cnn[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_cnn(cfg, cnn_shape, n_classes)\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=0,\n",
    "            validation_data=(X_fold_val, y_fold_val)\n",
    "        ) # acrescentado atributo validation_data para guardar cada dado de validação gerado no fit\n",
    "\n",
    "        loss_train_folds.append(history.history['loss'])\n",
    "        loss_val_folds.append(history.history['val_loss'])\n",
    "\n",
    "        historico_perdas['CNN'][cfg] = {\n",
    "            'train': np.mean(loss_train_folds, axis=0),\n",
    "            'val': np.mean(loss_val_folds, axis=0)\n",
    "        } # média das curvas entre os 10 folds para suavizar a curva\n",
    "\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuracia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'CNN', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b6829",
   "metadata": {},
   "source": [
    "### Rodando a KNN\n",
    "\n",
    "**Avaliação do KNN**: define-se a lista **k_values** contendo os hiperparâmetros de vizinhos a serem testados, variando de 1 a 20, conforme estipulado no artigo para comparação com as redes neurais. O loop itera sobre cada valor **k** para realizar a validação cruzada.\n",
    "\n",
    "**Loop de Validação Cruzada**: utiliza-se novamente o objeto **skf.split()** para garantir que os folds sejam idênticos aos experimentos anteriores. Uma distinção importante ocorre aqui: enquanto as redes neurais utilizavam rótulos one-hot encoded, o KNN utiliza os vetores de rótulos inteiros. Portanto, as variáveis de alvo **y_fold_train_labels** e **y_fold_val_labels** são extraídas diretamente de **y_train_int** (formato original 0-7) com base nos índices do fold atual.\n",
    "\n",
    "**Construção e Treinamento**: para cada fold, instancia-se o classificador **KNeighborsClassifier** configurado com o número de vizinhos **n_neighbors=k** da iteração atual. O método **knn.fit()** é chamado para ajustar o modelo aos dados de treino do fold. Diferente das redes neurais que requerem múltiplas épocas, o KNN é um algoritmo de aprendizado preguiçoso (*lazy learning*), onde o \"treinamento\" consiste basicamente no armazenamento dos dados para cálculos de distância posteriores.\n",
    "\n",
    "**Coleta de Métricas e Agregação**: a avaliação é feita através de **knn.score()**, que retorna diretamente a acurácia do modelo nos dados de validação. Esse valor é acumulado na lista **rel_acuraacia**. Ao final dos 10 folds, calculam-se a média (**mean_acc**) e o desvio padrão (**std_acc**). O dicionário de resultados é atualizado com o identificador 'KNN', o valor de K testado e as métricas estatísticas consolidadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01186c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "k_values = [1, 2, 5, 10, 20]\n",
    "print(\"\\nAvaliando KNN...\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    tf.keras.backend.clear_session()\n",
    "    rel_acuracia = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train_labels = y_train_int[train_idx]\n",
    "        y_fold_val_labels = y_train_int[val_idx]\n",
    "        knn.fit(X_fold_train, y_fold_train_labels)\n",
    "        acc = knn.score(X_fold_val, y_fold_val_labels)\n",
    "        rel_acuracia.append(acc)\n",
    "    \n",
    "    mean_acc = np.mean(rel_acuracia)\n",
    "    std_acc = np.std(rel_acuracia)\n",
    "    resultados.append({'Model': 'KNN', 'Config': f'K={k}', 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acurácia Média: {mean_acc:.4f}\")\n",
    "    print(f\"  -> Desvio Médio: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2e88b",
   "metadata": {},
   "source": [
    "### Comparando arquiteturas \n",
    "\n",
    "**Seleção dos Melhores Modelos**: primeiramente, transforma-se a lista de resultados obtidos na validação cruzada em um DataFrame do pandas (**resultados_df**) para manipulação estatística. Utiliza-se o método **.groupby()** agrupar os resultados por tipo de modelo ('MLP', 'CNN', 'KNN') e o **.idxmax()** para encontrar o índice da configuração que obteve a maior acurácia média em cada grupo. O resultado é armazenado em **melhores_por_tipo**, que contém apenas os três \"campeões\" (o melhor MLP, a melhor CNN e o melhor KNN).\n",
    "\n",
    "**Retreinamento e Teste Final**: inicia-se um loop para iterar sobre esses três modelos vencedores. É crucial notar que, nesta etapa, a validação cruzada já cumpriu seu papel de seleção. Agora, o objetivo é avaliar a performance real:\n",
    "* O modelo é reconstruído do zero com a configuração vencedora.\n",
    "* O treinamento (**fit**) é realizado utilizando **todo o conjunto de treino** (**X_train** e **y_train**), e não apenas parciais dos folds. Isso maximiza o aprendizado.\n",
    "* A avaliação definitiva ocorre no conjunto de teste (**X_test**), que representa os 10% de dados virgens separados no início do script.\n",
    "\n",
    "**Predição e Processamento de Saídas**:\n",
    "* Para **MLP e CNN**: como são redes neurais com saída Softmax, o método **.predict()** retorna o vetor **y_pred_probs** contendo as probabilidades para cada classe. Aplica-se a função **np.argmax(axis=1)** para identificar o índice da maior probabilidade, resultando no vetor **y_pred**, que contém a classe final prevista pelo modelo. Da mesma forma, **y_true** é obtido aplicando argmax no vetor de teste (que está em one-hot encoded) para recuperar o índice da classe real (onde está o bit 1).\n",
    "* Para **KNN**: o método **.predict()** já retorna diretamente as classes previstas, sem necessidade de argmax.\n",
    "\n",
    "**Geração da Matriz de Confusão**: com os vetores de classes reais (**y_true**) e previstos (**y_pred**) em mãos, calcula-se a matriz de confusão via **confusion_matrix()**. Para visualização, utiliza-se a biblioteca Seaborn (**sns.heatmap**) para plotar um mapa de calor, onde os eixos representam a \"Previsão\" e a \"Realidade\", facilitando a identificação de onde o modelo está acertando ou confundindo as classes (ex: confundindo falhas múltiplas).\n",
    "\n",
    "**Relatório Final**: o script exibe a **Acurácia Final** de cada tipo de modelo no conjunto de teste e, por fim, imprime um resumo completo ordenado pela acurácia média da validação, permitindo uma visão global do desempenho de todas as arquiteturas testadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1049c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado Final\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# índice de melhor modelo para cada tipo de modelo\n",
    "idx_melhores = resultados_df.groupby('Model')['Val_Acc_Mean'].idxmax()\n",
    "melhores_por_tipo = resultados_df.loc[idx_melhores]\n",
    "\n",
    "#print(\"\\n\" + \"=\"*40)\n",
    "#print(\"MELHORES POR TIPO\")\n",
    "#print(\"=\"*40)\n",
    "\n",
    "matrizes_confusao = {}\n",
    "metricas_modelos = []\n",
    "\n",
    "# treinando cada melhor modelo de novo e depois testando com o conjunto de teste\n",
    "for _, row in melhores_por_tipo.iterrows():\n",
    "    tipo_modelo = row['Model']\n",
    "    config = row['Config']\n",
    "    final_acc = 0\n",
    "\n",
    "    if tipo_modelo == 'MLP':\n",
    "        mlp_final = constroi_mlp(config, mlp_shape, n_classes)\n",
    "        mlp_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        mlp_final.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        loss, final_acc = mlp_final.evaluate(X_test, y_test, verbose=0)\n",
    "        y_pred_probs = mlp_final.predict(X_test) # saída da CNN, é o vetor de probabilidades gerado pela função softmax\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1) # pega a maior probabilidade da saída e me retorna a posição dela, ou seja, qual classe o modelo preveu\n",
    "        y_true = np.argmax(y_test, axis=1) # é a classe verdadeira do dado, retorno a posição de onde está o bit 1, pois está em one hot encoded \n",
    "        \n",
    "    elif tipo_modelo == 'CNN':\n",
    "        modelo_final = constroi_cnn(config, cnn_shape, n_classes)\n",
    "        modelo_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        modelo_final.fit(X_train_cnn, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        loss, final_acc = modelo_final.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "        y_pred_probs = modelo_final.predict(X_test_cnn)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1) \n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "    elif tipo_modelo == 'KNN':\n",
    "        k = int(config.split('=')[1])\n",
    "        modelo_final = KNeighborsClassifier(n_neighbors=k)\n",
    "        modelo_final.fit(X_train, y_train_int)\n",
    "        final_acc = modelo_final.score(X_test, y_test_int)\n",
    "        y_pred = modelo_final.predict(X_test)\n",
    "        y_true = y_test_int\n",
    "\n",
    "    # geração da matriz de confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    matrizes_confusao[tipo_modelo] = cm\n",
    "\n",
    "    # cálculo das medidas da matriz\n",
    "    n_classes_cm = cm.shape[0]\n",
    "    precisao_por_classe = []\n",
    "    recall_por_classe = []\n",
    "    f1_por_classe = []\n",
    "    \n",
    "    for i in range(n_classes_cm):\n",
    "        tp = cm[i, i]\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        \n",
    "        precisao = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        precisao_por_classe.append(precisao)\n",
    "        \n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        recall_por_classe.append(recall)\n",
    "        \n",
    "        f1 = 2 * (precisao * recall) / (precisao + recall) if (precisao + recall) > 0 else 0\n",
    "        f1_por_classe.append(f1)\n",
    "    \n",
    "    precisao_macro = np.mean(precisao_por_classe)\n",
    "    recall_macro = np.mean(recall_por_classe)\n",
    "    f1_macro = np.mean(f1_por_classe)\n",
    "    \n",
    "    acuracia = np.trace(cm) / np.sum(cm)\n",
    "    \n",
    "    metricas_modelos.append({\n",
    "        'Modelo': tipo_modelo,\n",
    "        'Configuracao': config,\n",
    "        'Acuracia': acuracia,\n",
    "        'Precisao_Macro': precisao_macro,\n",
    "        'Recall_Macro': recall_macro,\n",
    "        'F1_Macro': f1_macro\n",
    "    })\n",
    "\n",
    "    # plotando matriz de confusão com mapa de calor\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    print(f\"Matriz de Confusão para {tipo_modelo}:\")\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', \n",
    "                xticklabels=nomes_classes, yticklabels=nomes_classes)\n",
    "    plt.xlabel('Previsão', fontsize=12)\n",
    "    plt.ylabel('Realidade', fontsize=12)\n",
    "    plt.title(f'Matriz de Confusão de {tipo_modelo} - versão {config}', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    nome_saida = \"./images/matriz_confusao_\" + tipo_modelo + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    #plt.show()\n",
    "\n",
    "    #print(f\"-> Acurácia Final ({tipo_modelo}): {final_acc:.4f}\\n\")\n",
    "\n",
    "# melhores modelos\n",
    "df_metricas = pd.DataFrame(metricas_modelos)\n",
    "\n",
    "print(df_metricas.to_string(index=False))\n",
    "\n",
    "df_metricas_formatado = df_metricas.copy()\n",
    "df_metricas_formatado['Acuracia'] = df_metricas_formatado['Acuracia'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['Precisao_Macro'] = df_metricas_formatado['Precisao_Macro'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['Recall_Macro'] = df_metricas_formatado['Recall_Macro'].map('{:.4f}'.format)\n",
    "df_metricas_formatado['F1_Macro'] = df_metricas_formatado['F1_Macro'].map('{:.4f}'.format)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "dados_tabela = df_metricas_formatado.values\n",
    "cabecalhos = [\"Modelo\", \"Configuração\", \"Acurácia\", \"Precisão\\n(Macro)\", \"Recall\\n(Macro)\", \"F1-Score\\n(Macro)\"]\n",
    "\n",
    "table = ax.table(cellText=dados_tabela,\n",
    "                 colLabels=cabecalhos,\n",
    "                 loc='center',\n",
    "                 cellLoc='center',\n",
    "                 colWidths=[0.12, 0.18, 0.15, 0.18, 0.18, 0.19])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "CORES = {\n",
    "    \"MLP\": \"#001C53\", \n",
    "    \"CNN\": \"#008CFF\",  \n",
    "    \"KNN\": \"#74ADFC\"   \n",
    "}\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('white')\n",
    "    cell.set_linewidth(1.5)\n",
    "    \n",
    "    if row == 0:\n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "        cell.set_facecolor('#333333')\n",
    "        cell.set_height(0.08)\n",
    "    else:\n",
    "        idx_real = row - 1\n",
    "        modelo = df_metricas_formatado.iloc[idx_real][\"Modelo\"]\n",
    "        \n",
    "        if col == 0:\n",
    "            cor_fundo = CORES.get(modelo, \"#cccccc\")\n",
    "            cell.set_facecolor(cor_fundo)\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            if row % 2 == 0:\n",
    "                cell.set_facecolor('#f2f2f2')\n",
    "            else:\n",
    "                cell.set_facecolor('#ffffff')\n",
    "            cell.set_text_props(color='#333333')\n",
    "\n",
    "plt.suptitle('Análise de Desempenho dos Melhores Modelos', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "nome_saida = \"./images/analise_melhores_modelos.png\"\n",
    "plt.savefig(nome_saida, dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906385aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da matriz de confusão combinada \n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Matriz de Confusão Combinada\")\n",
    "print(\"=\"*40)\n",
    "if all(k in matrizes_confusao for k in ['MLP', 'CNN', 'KNN']):\n",
    "    cm_mlp = matrizes_confusao['MLP'].T\n",
    "    cm_cnn = matrizes_confusao['CNN'].T\n",
    "    cm_knn = matrizes_confusao['KNN'].T\n",
    "\n",
    "    matriz_combinada = np.empty((8, 8), dtype=object)\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            matriz_combinada[i, j] = f\"{cm_mlp[i,j]}/{cm_cnn[i,j]}/{cm_knn[i,j]}\"\n",
    "\n",
    "    labels_colunas = ['N', 'C', 'D', 'F', 'CD', 'CF', 'DF', 'CDF']\n",
    "    labels_linhas = [f'Prev {l}' for l in labels_colunas]\n",
    "\n",
    "    df_combinado = pd.DataFrame(matriz_combinada, index=labels_linhas, columns=labels_colunas)\n",
    "    #print(df_combinado)\n",
    "else: \n",
    "    print(\"Falha ao gerar matriz de confusão combinada.\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8)) \n",
    "\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "table = ax.table(cellText=df_combinado.values,\n",
    "                 colLabels=df_combinado.columns,\n",
    "                 rowLabels=df_combinado.index,\n",
    "                 loc='center',\n",
    "                 cellLoc='center',\n",
    "                 bbox=[0, 0, 1, 1])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11) \n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('black')\n",
    "    cell.set_linewidth(1)\n",
    "    \n",
    "    \n",
    "    if row == 0:\n",
    "        cell.set_facecolor(\"#001C53\") \n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "    \n",
    "    elif col == -1: \n",
    "        cell.set_facecolor(\"#001C53\") \n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "    \n",
    "    else:\n",
    "        if row == col + 1:\n",
    "            cell.set_facecolor(\"#d5ffb2\") \n",
    "            cell.set_text_props(weight='bold', color='black')\n",
    "        else:\n",
    "            texto = cell.get_text().get_text() \n",
    "            if texto != \"0/0/0\":\n",
    "                cell.set_facecolor(\"#fad0d0\") \n",
    "            else:\n",
    "                cell.set_facecolor('white') \n",
    "\n",
    "nome_saida_combinada = \"./images/matriz_confusao_COMBINADA.png\"\n",
    "plt.savefig(nome_saida_combinada, dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração de tabela para resultados da validação cruzada\n",
    "#print(\"\\nResumo Completo da Validação Cruzada:\")\n",
    "#print(resultados_df[['Model', 'Config', 'Val_Acc_Mean', 'Val_Acc_Std']].sort_values(by='Val_Acc_Mean', ascending=False))\n",
    "\n",
    "# preparação dos dados\n",
    "df = pd.DataFrame({\n",
    "    \"Modelo\": resultados_df['Model'],\n",
    "    \"Configuracao\": resultados_df['Config'],\n",
    "    \"Media_Acuracia\": resultados_df['Val_Acc_Mean'],\n",
    "    \"Media_DP\": resultados_df['Val_Acc_Std'],\n",
    "})\n",
    "df = df.sort_values(by='Media_Acuracia', ascending=False)\n",
    "df['Media_Acuracia'] = df['Media_Acuracia'].map('{:.5f}'.format)\n",
    "df['Media_DP'] = df['Media_DP'].map('{:.5f}'.format)\n",
    "\n",
    "CORES = {\n",
    "    \"MLP\": \"#001C53\", \n",
    "    \"CNN\": \"#008CFF\",  \n",
    "    \"KNN\": \"#74ADFC\"   \n",
    "}\n",
    "df[\"Cor\"] = df[\"Modelo\"].map(CORES)\n",
    "\n",
    "# fazendo tabelas\n",
    "def gerar_tabela(df_filtrado, nome_arquivo, titulo_modelo=\"\"):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 14)) \n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    dados_tabela = df_filtrado[[\"Modelo\", \"Configuracao\", \"Media_Acuracia\", \"Media_DP\"]].values\n",
    "    cabecalhos = [\"Modelo\", \"Configuração\", \"Acurácia Média\", \"Desvio-Padrão Médio\"]\n",
    "    \n",
    "    table = ax.table(cellText=dados_tabela,\n",
    "                     colLabels=cabecalhos,\n",
    "                     loc='center',\n",
    "                     cellLoc='center',\n",
    "                     colWidths=[0.15, 0.20, 0.30, 0.35])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2.0) \n",
    "    \n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('white')\n",
    "        cell.set_linewidth(1.5)\n",
    "        \n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight='bold', color='white', size=14)\n",
    "            cell.set_facecolor('#333333')\n",
    "            cell.set_height(0.06)\n",
    "        \n",
    "        else:\n",
    "            idx_real = row - 1\n",
    "            com_id = df_filtrado.iloc[idx_real][\"Modelo\"] \n",
    "            \n",
    "            if col == 2:\n",
    "                cor_fundo = CORES.get(com_id, \"#cccccc\")\n",
    "                cell.set_facecolor(cor_fundo)\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            \n",
    "            else:\n",
    "                if row % 2 == 0:\n",
    "                    cell.set_facecolor('#f2f2f2')\n",
    "                else:\n",
    "                    cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='#333333')\n",
    "    \n",
    "    nome_saida = f\"./images/{nome_arquivo}\"\n",
    "    plt.savefig(nome_saida, dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# gerando tabelas\n",
    "gerar_tabela(df, \"tabela_desempenhos_geral.png\")\n",
    "\n",
    "df_mlp = df[df[\"Modelo\"] == \"MLP\"].copy()\n",
    "df_mlp = df_mlp.sort_values(by='Media_Acuracia', ascending=False).reset_index(drop=True)\n",
    "gerar_tabela(df_mlp, \"tabela_desempenhos_MLP.png\", \"MLP\")\n",
    "\n",
    "df_cnn = df[df[\"Modelo\"] == \"CNN\"].copy()\n",
    "df_cnn = df_cnn.sort_values(by='Media_Acuracia', ascending=False).reset_index(drop=True)\n",
    "gerar_tabela(df_cnn, \"tabela_desempenhos_CNN.png\", \"CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0878e",
   "metadata": {},
   "source": [
    "### Visualização das Curvas de Aprendizado\n",
    "\n",
    "**Definição da Função de Plotagem**: define-se a função **plotar_curvas_loss()** que recebe como argumentos o dicionário de históricos acumulados (**historico**) e a chave do tipo de modelo a ser visualizado (**tipo_modelo**, ex: 'MLP' ou 'CNN'). O objetivo é gerar gráficos comparativos que permitam analisar a convergência e o ajuste dos modelos ao longo das épocas.\n",
    "\n",
    "**Configuração da Figura**: utiliza-se **plt.subplots(1, 2)** para criar uma figura contendo dois gráficos lado a lado: o primeiro (**ax1**) dedicado aos dados de treino e o segundo (**ax2**) aos dados de validação. As dimensões da figura são fixadas em 18x6 polegadas para garantir legibilidade. A variável **epochs** define o eixo X, representando o intervalo de épocas percorrido durante o treinamento.\n",
    "\n",
    "**Plotagem das Curvas de Treino**: itera-se sobre cada configuração (**cfg**) e suas respectivas métricas armazenadas no dicionário. No eixo **ax1**, plota-se a curva de perda média de treinamento (**curvas['train']**). Adicionam-se elementos visuais essenciais: título ('Função de Perda no treino'), rótulos dos eixos, legenda para identificar cada configuração ('4N', 'M1', etc.) e grade (**grid**) para facilitar a leitura dos valores.\n",
    "\n",
    "**Plotagem das Curvas de Validação**: repete-se a lógica de iteração para o eixo **ax2**, porém plotando a curva de perda média de validação (**curvas['val']**). Este gráfico é crucial para identificar comportamentos de *overfitting* (quando a perda de validação começa a subir enquanto a de treino cai) ou a estabilidade das diferentes arquiteturas em dados não vistos.\n",
    "\n",
    "**Execução**: por fim, a função é chamada explicitamente para os dois grupos de modelos, **'MLP'** e **'CNN'**, gerando as visualizações que permitem comparar qual topologia convergiu mais rápido e qual atingiu o menor erro final, replicando a análise visual apresentada na Figura 3 do artigo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando gráfico da função de perda a cada época no treinamento das MLP e CNN\n",
    "\n",
    "def plotar_curvas_loss(historico, tipo_modelo):\n",
    "    # treino\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    epochs = range(1, EPOCHS + 1)\n",
    "    \n",
    "    for cfg, curvas in historico[tipo_modelo].items():\n",
    "        ax1.plot(epochs, curvas['train'], label=f'{cfg}')\n",
    "    \n",
    "    ax1.set_title(f'Função de Perda no treino', fontsize=14)\n",
    "    ax1.set_xlabel('Épocas')\n",
    "    ax1.set_ylabel('Perda')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # validação\n",
    "    for cfg, curvas in historico[tipo_modelo].items():\n",
    "        ax2.plot(epochs, curvas['val'], label=f'{cfg}')\n",
    "    \n",
    "    ax2.set_title(f'Função de Perda na validação', fontsize=14)\n",
    "    ax2.set_xlabel('Épocas')\n",
    "    ax2.set_ylabel('Perda')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    nome_saida = \"./images/grafico_loss_curves\" + tipo_modelo + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "plotar_curvas_loss(historico_perdas, 'MLP')\n",
    "plotar_curvas_loss(historico_perdas, 'CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb82e5",
   "metadata": {},
   "source": [
    "### Análise de Componentes Principais (PCA)\n",
    "\n",
    "**Definição da Função de Plotagem**: implementa-se a função **gerar_pca()** para encapsular a lógica de redução de dimensionalidade e visualização. A função inicializa o objeto **PCA** com **n_components=2**, reduzindo as 201 dimensões originais (features de pressão) para apenas 2 componentes principais, permitindo a plotagem em um plano cartesiano.\n",
    "\n",
    "**Estruturação dos Dados**: o método **fit_transform()** é aplicado aos dados de entrada para calcular os autovetores e projetar os dados no novo espaço reduzido. O resultado é organizado em um DataFrame do pandas contendo as colunas 'PCA1' e 'PCA2', além da coluna 'Classe' com os rótulos verdadeiros (**true_labels**), o que facilita o agrupamento visual.\n",
    "\n",
    "**Visualização por Dispersão**: utiliza-se um loop para iterar sobre cada classe única, plotando os pontos correspondentes via **plt.scatter()**. Isso garante que cada tipo de falha seja representado por uma cor distinta e associada ao seu nome legível (via lista **nomes_classes**). O gráfico é finalizado com rótulos de eixos, título personalizado, legenda e grade.\n",
    "\n",
    "**Visualização dos Dados Brutos (Baseline)**: a primeira chamada da função é feita passando o conjunto de teste original (**X_test**) e os rótulos inteiros (**y_test_int**). Este gráfico serve como linha de base, mostrando como as classes estão distribuídas naturalmente no espaço de entrada antes de qualquer processamento pela rede neural, correspondendo à parte superior da Figura 4 do artigo.\n",
    "\n",
    "**Extração de Características (Hidden Layer)**: para visualizar o aprendizado da rede e contornar limitações de acesso ao grafo do modelo Sequential, reconstrói-se o fluxo de dados manualmente via API Funcional. Define-se um novo tensor de entrada (**tf.keras.Input**) e itera-se sobre as camadas já treinadas do MLP (**mlp_final.layers[:-1]**), aplicando-as sequencialmente até a penúltima camada. Um novo modelo extrator (**saida_oculta**) é instanciado conectando essa nova entrada à saída processada, isolando as representações internas (features) antes da classificação Softmax.\n",
    "\n",
    "**Visualização das Representações Latentes**: os dados de teste são passados por esse modelo reconstruído (**saida_oculta.predict**), gerando o conjunto **X_saida_oculta**. A função **gerar_pca()** é chamada novamente com esses novos dados. O gráfico resultante demonstra a capacidade da rede neural de transformar o espaço de dados, agrupando classes que antes estavam sobrepostas e facilitando a classificação linear final, correspondendo à parte inferior da Figura 4 do artigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração do PCA para visualização da separação das classes usando o melhor MLP\n",
    "\n",
    "def gerar_pca(dados, true_labels, titulo, nome_img):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(dados)\n",
    "\n",
    "    df = pd.DataFrame(data=X_pca, columns=['PCA1','PCA2'])\n",
    "    df['Classe'] = true_labels\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    for classe in sorted(df['Classe'].unique()):\n",
    "        subset = df[df['Classe'] == classe]\n",
    "        plt.scatter(\n",
    "            subset['PCA2'],\n",
    "            subset['PCA1'],\n",
    "            label=nomes_classes[classe],\n",
    "            alpha=0.6,\n",
    "            marker='o'\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('PCA2', fontsize=12)\n",
    "    plt.ylabel('PCA1', fontsize=12)\n",
    "    plt.title(titulo, fontsize=14)\n",
    "    plt.legend(title='Classe', markerscale=1.5, fontsize=8)\n",
    "    plt.grid(True)\n",
    "    nome_saida = \"./images/PCA\" + nome_img + \".png\"\n",
    "    plt.savefig(nome_saida, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "gerar_pca(dados=X_test, true_labels=y_test_int, titulo='Decomposição dos Inputs antes Camada Oculta (PCA)', nome_img='_pre_camada_oculta')\n",
    "\n",
    "# Visualizar após a camada oculta nome_img='_pos_camada_oculta'\n",
    "input_tensor = tf.keras.Input(shape=(n_features,))\n",
    "\n",
    "x = input_tensor\n",
    "for layer in mlp_final.layers[:-1]:\n",
    "    x = layer(x)\n",
    "\n",
    "saida_oculta = tf.keras.models.Model(\n",
    "    inputs=input_tensor,\n",
    "    outputs=x\n",
    ")\n",
    "\n",
    "X_saida_oculta = saida_oculta.predict(X_test)\n",
    "\n",
    "gerar_pca(dados=X_saida_oculta, true_labels=y_test_int, titulo='Decomposição dos Inputs após Camada Oculta (PCA)', nome_img='_pos_camada_oculta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabalho_neural_networks",
   "language": "python",
   "name": "neural_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
