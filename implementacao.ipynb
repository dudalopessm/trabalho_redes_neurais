{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2a7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2307e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARQUIVOS\n",
    "ATTRIBUTES_FILE = './dataset/attributes.csv'\n",
    "LABELS_FILE = './dataset/label.csv'          \n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: 'Normal',\n",
    "    1: 'Charge',\n",
    "    2: 'Discharge',\n",
    "    3: 'Friction',\n",
    "    4: 'Charge Discharge',\n",
    "    5: 'Charge Friction',\n",
    "    6: 'Discharge Friction',\n",
    "    7: 'Charge Discharge Friction'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87d70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para os dados aleatorios se repetirem\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ea797",
   "metadata": {},
   "source": [
    "**carrega_dados**\n",
    "\n",
    "X.shape[0]: número de linhas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de amostras disponíveis.\n",
    "\n",
    "X.shape[1]: número de colunas do array numPy com todos os dados de entrada. nesse caso, seria a quantidade de colunas do csv de amostras. ou seja, quantas variações de tempo uma única amostra possui. \n",
    "\n",
    "X: \n",
    "| Amostra | feature_1 | feature_2 | ... | feature_201  |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| amostra 1 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 2 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "| amostra 3 | valor_pressão_f1 | valor_pressão_f2 | ... | valor_pressão_f201 |\n",
    "|  ...      |       ...        |         ...      | ... |           ...      |\n",
    "\n",
    "tf.keras.utils.to_categorical(y, num_classes=num_classes): converte rótulos de classes inteiros para formato one-hot encoded. é armazenado em uma array numPy. seu tamanho é linhas_amostras x nro_classes. \n",
    "\n",
    "y_categorical:\n",
    "| Amostra | Neurônio 1 (Normal) | Neurônio 2 (Charge) | ... | Neurônio 8 (All Faults) |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| Linha 1 | 1 | 0 | ... | 0 |\n",
    "| Linha 2 | 0 | 0 | ... | 1 |\n",
    "| Linha 3 | 0 | 0 | ... | 0 |\n",
    "|  ...    | 0 | 0 | ... | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7315d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(attr_caminho, lbl_caminho):\n",
    "\n",
    "    print(f\"Lendo atributos: {attr_caminho}\")\n",
    "    print(f\"Lendo labels: {lbl_caminho}\")\n",
    "    \n",
    "    X_df = pd.read_csv(attr_caminho)\n",
    "    y_df = pd.read_csv(lbl_caminho)\n",
    "\n",
    "    # converte para vetor\n",
    "    X = X_df.values\n",
    "    y = y_df.values.flatten() \n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    print(f\"Dataset carregado com sucesso:\")\n",
    "    print(f\" - Amostras: {X.shape[0]}\")\n",
    "    print(f\" - Features (Timestamps): {num_features}\")\n",
    "    print(f\" - Classes únicas encontradas: {num_classes} {np.unique(y)}\")\n",
    "\n",
    "    # One-hot para redes neurais\n",
    "    y_categorical = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "    \n",
    "    return X, y_categorical, y, num_features, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2413d",
   "metadata": {},
   "source": [
    "**constroi_mlp**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ae7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELOS (Tópico 3.4)\n",
    "\n",
    "def constroi_mlp(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == '4N':\n",
    "        model.add(layers.Dense(4, activation='relu'))\n",
    "    elif config_name == '8N':\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "    elif config_name == '16N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "    elif config_name == '32N':\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif config_name == '16-8N':\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "        \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0591fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constroi_cnn(config_name, shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=shape))\n",
    "    \n",
    "    if config_name == 'M1':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M2':\n",
    "        model.add(layers.Conv1D(filters=2, kernel_size=8, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M3':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=16, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M4':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=8))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "        \n",
    "    elif config_name == 'M5':\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=4))\n",
    "        model.add(layers.Conv1D(filters=1, kernel_size=8, padding='same'))\n",
    "        model.add(layers.AveragePooling1D(pool_size=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo atributos: ./dataset/attributes.csv\n",
      "Lendo labels: ./dataset/label.csv\n",
      "Dataset carregado com sucesso:\n",
      " - Amostras: 8000\n",
      " - Features (Timestamps): 201\n",
      " - Classes únicas encontradas: 8 [0 1 2 3 4 5 6 7]\n",
      "\n",
      "Iniciando Validação Cruzada (K=10)...\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENTOS\n",
    "    \n",
    "X, y_cat, y_integers, n_features, n_classes = carrega_dados(ATTRIBUTES_FILE, LABELS_FILE)\n",
    "\n",
    "# divisao treino/teste (10% Teste)\n",
    "X_train, X_test, y_train, y_test, y_train_int, y_test_int = train_test_split(\n",
    "    X, y_cat, y_integers, test_size=0.10, stratify=y_integers, random_state=42\n",
    ")\n",
    "\n",
    "# CNN: (samples, timesteps, features=1)\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "mlp_shape = (n_features,)\n",
    "cnn_shape = (n_features, 1)\n",
    "\n",
    "EPOCHS = 50 \n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 10\n",
    "\n",
    "resultados = []\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nIniciando Validação Cruzada (K={K_FOLDS})...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando MLP: 4N\n",
      "  -> Acc Média: 0.9921\n",
      "Avaliando MLP: 8N\n",
      "  -> Acc Média: 0.9958\n",
      "Avaliando MLP: 16N\n",
      "  -> Acc Média: 0.9950\n",
      "Avaliando MLP: 32N\n",
      "  -> Acc Média: 0.9942\n",
      "Avaliando MLP: 16-8N\n",
      "  -> Acc Média: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "confiiguracoes_mlp = ['4N', '8N', '16N', '32N', '16-8N']\n",
    "for cfg in confiiguracoes_mlp:\n",
    "    print(f\"Avaliando MLP: {cfg}\")\n",
    "    rel_acuraacia = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_mlp(cfg, mlp_shape, n_classes)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_fold_train, y_fold_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuraacia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuraacia)\n",
    "    std_acc = np.std(rel_acuraacia)\n",
    "    resultados.append({'Model': 'MLP', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acc Média: {mean_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c2701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando CNN: M1\n",
      "  -> Acc Média: 0.9958\n",
      "Avaliando CNN: M2\n",
      "  -> Acc Média: 0.9956\n",
      "Avaliando CNN: M3\n",
      "  -> Acc Média: 0.9968\n",
      "Avaliando CNN: M4\n",
      "  -> Acc Média: 0.9936\n",
      "Avaliando CNN: M5\n",
      "  -> Acc Média: 0.9933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CNN\n",
    "confiiguracoes_cnn = ['M1', 'M2', 'M3', 'M4', 'M5']\n",
    "for cfg in confiiguracoes_cnn:\n",
    "    print(f\"Avaliando CNN: {cfg}\")\n",
    "    rel_acuraacia = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train_cnn[train_idx], X_train_cnn[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = constroi_cnn(cfg, cnn_shape, n_classes)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_fold_train, y_fold_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "        _, acc = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        rel_acuraacia.append(acc)\n",
    "        \n",
    "    mean_acc = np.mean(rel_acuraacia)\n",
    "    std_acc = np.std(rel_acuraacia)\n",
    "    resultados.append({'Model': 'CNN', 'Config': cfg, 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> Acc Média: {mean_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01186c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliando KNN...\n",
      "  -> KNN K=1: 0.8826\n",
      "  -> KNN K=2: 0.8553\n",
      "  -> KNN K=5: 0.8862\n",
      "  -> KNN K=10: 0.8753\n",
      "  -> KNN K=20: 0.8597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNN\n",
    "k_values = [1, 2, 5, 10, 20]\n",
    "print(\"\\nAvaliando KNN...\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    rel_acuraacia = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train_int):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train_labels = y_train_int[train_idx]\n",
    "        y_fold_val_labels = y_train_int[val_idx]\n",
    "        knn.fit(X_fold_train, y_fold_train_labels)\n",
    "        acc = knn.score(X_fold_val, y_fold_val_labels)\n",
    "        rel_acuraacia.append(acc)\n",
    "    \n",
    "    mean_acc = np.mean(rel_acuraacia)\n",
    "    std_acc = np.std(rel_acuraacia)\n",
    "    resultados.append({'Model': 'KNN', 'Config': f'K={k}', 'Val_Acc_Mean': mean_acc, 'Val_Acc_Std': std_acc})\n",
    "    print(f\"  -> KNN K={k}: {mean_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb9d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MELHOR MODELO: CNN (M3)\n",
      "========================================\n",
      "Acurácia Final no Teste (10%): 0.9937\n",
      "\n",
      "Resumo Completo:\n",
      "   Model Config  Val_Acc_Mean  Val_Acc_Std\n",
      "0    MLP     4N      0.992083     0.002488\n",
      "1    MLP     8N      0.995833     0.002778\n",
      "2    MLP    16N      0.995000     0.003298\n",
      "3    MLP    32N      0.994167     0.004383\n",
      "4    MLP  16-8N      0.995278     0.003632\n",
      "5    CNN     M1      0.995833     0.003287\n",
      "6    CNN     M2      0.995556     0.002764\n",
      "7    CNN     M3      0.996806     0.004028\n",
      "8    CNN     M4      0.993611     0.002860\n",
      "9    CNN     M5      0.993333     0.004640\n",
      "10   KNN    K=1      0.882639     0.017070\n",
      "11   KNN    K=2      0.855278     0.011782\n",
      "12   KNN    K=5      0.886250     0.013909\n",
      "13   KNN   K=10      0.875278     0.007212\n",
      "14   KNN   K=20      0.859722     0.010282\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resultado Final\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "melhor_rodada = resultados_df.loc[resultados_df['Val_Acc_Mean'].idxmax()]\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"MELHOR MODELO: {melhor_rodada['Model']} ({melhor_rodada['Config']})\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "final_acc = 0\n",
    "if melhor_rodada['Model'] == 'MLP':\n",
    "    modelo_final = constroi_mlp(melhor_rodada['Config'], mlp_shape, n_classes)\n",
    "    modelo_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    modelo_final.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    loss, final_acc = modelo_final.evaluate(X_test, y_test, verbose=0)\n",
    "elif melhor_rodada['Model'] == 'CNN':\n",
    "    modelo_final = constroi_cnn(melhor_rodada['Config'], cnn_shape, n_classes)\n",
    "    modelo_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    modelo_final.fit(X_train_cnn, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    loss, final_acc = modelo_final.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "elif melhor_rodada['Model'] == 'KNN':\n",
    "    k = int(melhor_rodada['Config'].split('=')[1])\n",
    "    modelo_final = KNeighborsClassifier(n_neighbors=k)\n",
    "    modelo_final.fit(X_train, y_train_int)\n",
    "    final_acc = modelo_final.score(X_test, y_test_int)\n",
    "\n",
    "print(f\"Acurácia Final no Teste (10%): {final_acc:.4f}\")\n",
    "print(\"\\nResumo Completo:\")\n",
    "print(resultados_df[['Model', 'Config', 'Val_Acc_Mean', 'Val_Acc_Std']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabalho_neural_networks",
   "language": "python",
   "name": "neural_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
